{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"G00x - Generalizable Germline-Targeting Clinical Trial Pipeline"},{"location":"#about","title":"About","text":"<p>This is the code for the G00x pipelines including G002 and G003. It is an all-in-one pipeline and analysis that parses, validates, calculates frequencies, runs 10X and combines all analysis into a plottable dataframe.</p> <p>Source Code: https://github.com/schieflab//G002-and-G003</p>"},{"location":"#quick-start-installation","title":"Quick start installation","text":"<p>While not necessary, we highly recommend using the conda open-source package and environment manager. This allows you to make an environment without destroying your system installed python environment.</p> <p>Miniconda installers</p> <p>Mac command line installer</p> <p>Mac GUI installer</p> <p>Linux command line installer</p> <p>To install G00x package, use the following</p> <pre><code>clone the repository\n$ git clone https://github.com/schieflab//G002-and-G003\n\nchange into /G002-and-G003\n$ cd /G002-and-G003\n\ncreate an environment\n$ conda create -n g00x python==3.10.6 poetry==1.3.1 -y\n\nactivate the environment\n$ conda activate g00x\n\n\nuse poetry to install\n$ poetry install --with dev\n\n$ g00x --help\nUsage: g00x [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --logging-level TEXT  Set logging level\n  --help                Show this message and exit.\n\nCommands:\n  g002  Run the G002 commands of G00x\n  g003  Run the G003 commands of G00x\n\nrun g002 part of g00x\n$ g00x g002 --help\n\nUsage: g00x g002 [OPTIONS] COMMAND [ARGS]...\n\n  Run the G002 commands of G00x\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  analysis  Commands that will analyze the complete pipeline\n  box       Commands that will interact with NIHBox\n  globus    Commands that will interact with Globus\n  pipeline  Run the 10x pipeline including the SADIE AIRR output\n  validate  Commands that will validate the file have all appropriate...\n</code></pre>"},{"location":"#g002-where-to-go","title":"G002 where to go","text":"<p>\ud83d\udcca G002 Data Transfer and use the raw data \u27a1\ufe0f Take me!</p> <p>\u2705 G002 Validation Validate your data structures \u27a1\ufe0f Take me!</p> <p>\ud83e\uddea G002 Pipeline Use the G002 flow and sequencing pipeline \u27a1\ufe0f Take me!</p> <p>\ud83d\udd0d G002 Analysis Analyze the dataframes and make figures \u27a1\ufe0f Take me!</p>"},{"location":"#g003-where-to-go","title":"G003 where to go","text":"<p>\ud83d\udcca G003 Data Transfer and use the raw data \u27a1\ufe0f Take me!</p> <p>\u2705 G003 Validation Validate your data structures \u27a1\ufe0f Take me!</p> <p>\ud83e\uddea G003 Pipeline Use the G003 flow and sequencing pipeline \u27a1\ufe0f Take me!</p> <p>\ud83d\udd0d G003 Analysis Analyze the dataframes and make figures \u27a1\ufe0f Take me!</p>"},{"location":"Contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to this project. To contribute to this repository, please follow the steps below: 1. Fork the repository 2. Clone the forked repository to your local machine 3. Create a new branch for your changes 4. Make your changes, commit them, and push the branch to your forked repository 5. Create a pull request to the original repository 6. Wait for the pull request to be reviewed and merged 7. If there are any issues with your pull request, address them and push the changes to your forked repository 8. Once the pull request is approved, we will merge it into the original repository</p> <p>You can also contribute by reporting issues, suggesting features, or improving the documentation. If you have any questions or need help, contact the repository maintainers.</p>"},{"location":"g002_analysis/","title":"Analysis","text":"<p>The analysis of the data is can be done after the pipeline.</p> <p></p>"},{"location":"g002_analysis/#getting-an-analysis-report","title":"Getting an analysis report","text":"<p>The analysis report is the sequencing and flow cytometry data combined. It has all count and frequencies of the flow data and the frequencies of VRC01 class among the sequences. It will then combine those frequencies to give a final frequency of VRC01 among some cell type phenotype.</p> :material-console-line: Command Line Usage :material-api: Python <p>The following will produce an analysis report and combine data. It will output a flow</p> <p> <pre><code>$ g00x g002 analysis report -s g002/G002/output/final_df.feather -f g002/G002/output/flow_output.feather -o g002/G002/output/flow_and_sequencing\n</code></pre> </p> <pre><code>from g00x.data import Data\nfrom g00x.analysis.report import combine_seq_and_flow\n\ndata = Data()\nsequencing_dataframe_path = \"g002/G002/output/final_df.feather\"\nflow_dataframe_path = \"g002/G002/output/flow_output.feather\"\n\n# input the sequeences to feather\nsequencing_dataframe = pd.read_feather(sequencing_dataframe_path)\nflow_dataframe = pd.read_feather(flow_dataframe_path)\n\n# generate three different dataframe\nseq_and_flow_df, seq_and_flow_df_long_name, seq_and_flow_df_long_form = combine_seq_and_flow(\n    data, sequencing_dataframe, flow_dataframe\n)\n</code></pre> <p>This will output a <code>flow_and_sequencing.feather</code>, <code>flow_and_sequencing_long_names.feather</code>, and <code>flow_and_sequencing_long_form.feather</code>.</p> <p>The long form is the long form dataframe:</p> run_purpose run_date pubID ptid group weeks visit_id probe_set sample_type value_type value short_name long_name pbmc_gate_expression 319 PreS 2022-10-24 G002-516 G002516 1 16 V270 Cg28v2 PBMC count 418948 B cells_cell_count B cells_cell_count P4 2326 PreS 2022-10-31 G002-884 G002884 3 -5 V091 eODGT8 PBMC count 18298 IgG-IgA-/IgM+/KO-_cell_count IgG-IgA-/IgM+/KO-_cell_count P25 <p>The long names are pivoted:</p> run_purpose run_date pubID ptid group weeks visit_id probe_set sample_type B cells_cell_count CD19+/CD20-/CD27+CD38+/Antigen++/KO-_cell_count CD19+/CD20-/CD27+CD38+/Antigen++_cell_count CD19+/CD20-/CD27+CD38+/KO-/Epitope++_cell_count CD19+/CD20-/CD27+CD38+/KO-_cell_count CD19+/CD20-/CD27+CD38+_cell_count CD19+/CD20-_cell_count CD19+_cell_count Dump-_cell_count Frequency of IGD- sequences that are VRC01-class Frequency of IGHA sequences that are VRC01-class Frequency of IGHD sequences that are VRC01-class Frequency of IGHG sequences that are VRC01-class Frequency of IGHM sequences that are VRC01-class Frequency of VRC01-class sequences among IgA Frequency of VRC01-class sequences among IgD- Frequency of VRC01-class sequences among IgG Frequency of VRC01-class sequences among IgM IgD+ B cells_cell_count IgD+/Antigen++/KO-_cell_count IgD+/Antigen++_cell_count IgD+/KO-/Epitope++_cell_count IgD+/KO-_cell_count IgD- B cells_cell_count IgD-/Antigen++/KO-_cell_count IgD-/Antigen++_cell_count IgD-/KO-/Epitope++_cell_count IgD-/KO-_cell_count IgG-IgA-/IgM+/Antigen++/KO-_cell_count IgG-IgA-/IgM+/Antigen++_cell_count IgG-IgA-/IgM+/KO-/Epitope++_cell_count IgG-IgA-/IgM+/KO-_cell_count IgG-IgA-/IgM+_cell_count IgG-IgA-_cell_count IgG-IgM-/IgA+/Antigen++/KO-_cell_count IgG-IgM-/IgA+/Antigen++_cell_count IgG-IgM-/IgA+/KO-/Epitope++_cell_count IgG-IgM-/IgA+/KO-_cell_count IgG-IgM-/IgA+_cell_count IgG-IgM-IgD-_cell_count IgM-IgA-/IgG+/Antigen++/KO-_cell_count IgM-IgA-/IgG+/Antigen++_cell_count IgM-IgA-/IgG+/KO-/Epitope++_cell_count IgM-IgA-/IgG+/KO-_cell_count IgM-IgA-/IgG+_cell_count IgM-IgA-_cell_count Lymphocytes_cell_count Number of IGD- sequences that are VRC01-class Number of IGHA sequences that are VRC01-class Number of IGHD sequences that are VRC01-class Number of IGHG sequences that are VRC01-class Number of IGHM sequences that are VRC01-class Percent IgA^{+}KO^- among Ag^{++} Percent IgD^{-}KO^{-} among Ag^{++} Percent IgG^{+}KO^- among Ag^{++} Percent IgM{+}KO^- among Ag^{++} Percent PB{+}KO^- among Ag^{++} Percent antigen-specific among IgD^- Percent antigen-specific among IgG^{+} Percent antigen-specific among IgM Percent epitope-specific (KO^-Ag^{++}) among IgA^{+} Percent epitope-specific (KO^-Ag^{++}) among IgD^- Percent epitope-specific (KO^-Ag^{++}) among IgG^{+} Percent epitope-specific (KO^-Ag^{++}) among IgM Percent epitope-specific (KO^-Ag^{++}) among PB Percent of antigen-specific among IgA^{+} Percent of antigen-specific among PB Singlets_cell_count 46 PreS 2022-10-31 G002-884 G002884 3 16 V500 eODGT8 PBMC 415845 0 5 0 1915 1931 4146 414462 472678 nan nan nan nan nan nan nan nan nan 255368 117 177 117 253414 161568 391 1504 394 158975 3 4 3 16985 17142 25395 13 22 13 38244 38507 46508 340 1383 340 92983 94964 102932 555794 nan nan nan nan nan 59.0909 25.9973 24.5842 0.0176626 0 0.930877 1.45634 75 0.0337601 0.24386 0.35803 0.0175009 0 0.0571325 0.258933 550934 2 PreS 2022-08-25 G002-516 G002516 1 8 V200 eODGT8 PBMC 1.2981e+06 1 1 1 15503 16641 121174 1.27163e+06 1.34031e+06 nan nan nan nan nan nan nan nan nan 864372 456 718 409 801485 433730 554 1070 469 404609 38 54 35 69781 74779 121496 47 97 51 96230 103053 148151 336 709 288 189984 203562 254258 1.37136e+06 nan nan nan nan nan 48.4536 51.7757 47.3907 0.0544561 100 0.246697 0.348297 64.8148 0.0494891 0.108132 0.14148 0.0468046 0.00600925 0.0941263 0.00600925 1.36246e+06 <p>The short names are also pivoted</p> run_purpose run_date pubID ptid group weeks visit_id probe_set sample_type B cells_cell_count CD19+/CD20-/CD27+CD38+/Antigen++/KO-_cell_count CD19+/CD20-/CD27+CD38+/Antigen++_cell_count CD19+/CD20-/CD27+CD38+/KO-/Epitope++_cell_count CD19+/CD20-/CD27+CD38+/KO-_cell_count CD19+/CD20-/CD27+CD38+_cell_count CD19+/CD20-_cell_count CD19+_cell_count Dump-_cell_count IgD+ B cells_cell_count IgD+/Antigen++/KO-_cell_count IgD+/Antigen++_cell_count IgD+/KO-/Epitope++_cell_count IgD+/KO-_cell_count IgD- B cells_cell_count IgD-/Antigen++/KO-_cell_count IgD-/Antigen++_cell_count IgD-/KO-/Epitope++_cell_count IgD-/KO-_cell_count IgG-IgA-/IgM+/Antigen++/KO-_cell_count IgG-IgA-/IgM+/Antigen++_cell_count IgG-IgA-/IgM+/KO-/Epitope++_cell_count IgG-IgA-/IgM+/KO-_cell_count IgG-IgA-/IgM+_cell_count IgG-IgA-_cell_count IgG-IgM-/IgA+/Antigen++/KO-_cell_count IgG-IgM-/IgA+/Antigen++_cell_count IgG-IgM-/IgA+/KO-/Epitope++_cell_count IgG-IgM-/IgA+/KO-_cell_count IgG-IgM-/IgA+_cell_count IgG-IgM-IgD-_cell_count IgM-IgA-/IgG+/Antigen++/KO-_cell_count IgM-IgA-/IgG+/Antigen++_cell_count IgM-IgA-/IgG+/KO-/Epitope++_cell_count IgM-IgA-/IgG+/KO-_cell_count IgM-IgA-/IgG+_cell_count IgM-IgA-_cell_count Lymphocytes_cell_count Singlets_cell_count num_IGHA_vrc01_class_sequences num_IGHD_vrc01_class_sequences num_IGHG_vrc01_class_sequences num_IGHM_vrc01_class_sequences num_igdneg_vrc01_class_sequences percent_IGHA_vrc01_class_sequences percent_IGHD_vrc01_class_sequences percent_IGHG_vrc01_class_sequences percent_IGHM_vrc01_class_sequences percent_ag_among_iga percent_ag_among_igd_neg percent_ag_among_igg percent_ag_among_igm percent_ag_among_pb percent_ep_among_iga percent_ep_among_igd_neg percent_ep_among_igg percent_ep_among_igm percent_ep_among_pb percent_igako_among_ag percent_igdneg_vrc01_class_sequences percent_iggko_among_ag percent_igmko_among_ag percent_ko_among_ag_igd_neg percent_pbko_among_ag percent_vrc01_among_iga percent_vrc01_among_igd_neg percent_vrc01_among_igg percent_vrc01_among_igm 85 PreS 2022-11-08 G002-852 G002852 1 8 V200 eODGT8 PBMC 992632 3 3 3 1357 1374 8892 982808 1.02292e+06 705541 833 1131 833 698255 289703 930 2231 937 285912 44 57 44 30308 30561 44012 43 82 44 84999 85750 98725 634 1548 634 147423 149684 162491 1.0971e+06 1.08986e+06 nan nan nan nan nan nan nan nan nan 0.0956268 0.770099 1.03418 77.193 0.218341 0.051312 0.323435 0.423559 0.143974 0.218341 52.439 nan 40.9561 0.145176 41.6853 100 nan nan nan nan 84 PreS 2022-11-08 G002-852 G002852 1 4 V160 eODGT8 PBMC 1.10867e+06 79 131 79 1691 1782 10146 1.09833e+06 1.15407e+06 820575 2017 3147 2017 813873 290959 1817 3937 1830 287026 80 145 80 33509 33766 47452 78 119 80 84703 85268 98461 792 1659 792 143728 145494 158611 1.23712e+06 1.2314e+06 nan nan nan nan nan nan nan nan nan 0.13956 1.35311 1.14025 55.1724 7.35129 0.0938218 0.628955 0.544352 0.236925 4.43322 65.5462 nan 47.7396 0.238742 46.1519 60.3053 nan nan nan nan"},{"location":"g002_analysis/#count","title":"Count","text":"<p>Easily count the amount of samples we have.</p> :material-console-line: Command Line Usage <p> <pre><code>$ g00x g002 analysis count -f g002/G002/output/flow_output.feather -o count\n</code></pre> </p> <p>This will output:</p> <p> </p>"},{"location":"g002_cloud/","title":"Cloud management","text":"<p>At this moment we are using terraform to describe the cloud instances we are requisitioning.</p>"},{"location":"g002_cloud/#terraform","title":"Terraform","text":"<p>Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.</p>"},{"location":"g002_cloud/#installation","title":"Installation","text":"<p>For full installation instructions, go to https://learn.hashicorp.com/tutorials/terraform/install-cli</p>"},{"location":"g002_cloud/#mac","title":"Mac","text":"<p>For mac use homebrew to install</p> <pre><code>$ brew tap hashicorp/tap\n$ brew install hashicorp/tap/terraform\n$ brew update\n</code></pre>"},{"location":"g002_cloud/#starting-an-instance","title":"Starting an instance","text":"<p>To start an instance, you need to have a valid AWS account and have the credentials in your environment. You can use the following command to start an instance.</p> <pre><code>$cd terraform/oregon\n$ terraform init\n$ terraform apply\n</code></pre> <p>Note</p> <p>This will start an instance as recorded in single_ec2.tf. That is a structured terraform file that describes the resources you need:</p> <pre><code># tells terraform you are using AWS\nterraform {\nrequired_providers {\n    aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~&gt; 3.27\"\n    }\n}\n\nrequired_version = \"&gt;= 0.14.9\"\n}\n\n# Tells which profile to use in your credentials and to start the instance in Oregon\nprovider \"aws\" {\nprofile = \"default\"\nregion  = \"us-west-2\" # oregon\n}\n\n\n# associate a static IP address with your instnace\nresource \"aws_eip_association\" \"eip_assoc\" {\ninstance_id         = aws_instance.g00x_dedicated_instance.id # can assocaite this with an instnace or network interface\npublic_ip           = \"44.240.169.113\"  #elastic IP\nallow_reassociation = true\n}\n\n\n\n# This is the instance you want to start\nresource \"aws_instance\" \"g00x_dedicated_instance\" {\n    ami = \"ami-0fd14da38e402236e\" # Ubuntu LTS 20.04 - with Luster Kernel and CellRanger\n\n    # what size of the instnace\n    instance_type = \"m5.12xlarge\"\n    key_name      = \"G00x\"\n    network_interface {\n        network_interface_id  = \"eni-06717892d1883626c\" #network interface, logical grouping of vpcid, subnet and security for G00x\n    device_index          = 0\n    delete_on_termination = false\n    }\n    root_block_device {\n    delete_on_termination = true\n    volume_size           = 500\n    tags                  = { Name = \"G00x Root Volume\" }\n    }\n\n    # this is the startup file we will use\n    user_data = file(\"startup.sh\") # file directive can install stuff\n    tags = {\n    Name = \"G00x Oregon\"\n    }\n    }\n\nresource \"aws_eip\" \"example\" {\nvpc = true\n}\n</code></pre>"},{"location":"g002_cloud/#stopping-an-instance","title":"Stopping an instance","text":"<p>To stop a terraformed instance, we can simply destroy it. This will not delete anything since we are using an distributed FSx file system.</p> <pre><code>$ terraform destroy\n</code></pre>"},{"location":"g002_data/","title":"Contents","text":"<ul> <li>Contents</li> <li>Summary</li> <li>Simple Setup<ul> <li>Getting Data from AWS</li> <li>Obtaining AWS credentials.</li> <li>AWS G002</li> <li>AWS S3 Copy Specific Files</li> <li>AWS S3 Sync All Files</li> </ul> </li> <li>Advanced Setup</li> <li>AWS Instance Setup<ul> <li>Box Auto Sync</li> <li>Globus Auto Sync</li> </ul> </li> <li>Local Machine Setup<ul> <li>Mounting Box</li> <li>Rclone</li> <li>Mounting Globus</li> </ul> </li> </ul>"},{"location":"g002_data/#summary","title":"Summary","text":"<p>AWS S3 buckets contain a stable version of the data. The data is organized by sequencing, sorting and output. To get the data using Simple Setup, you need the AWS CLI.</p> <p>If you are a developer and would like the most recent version of the data with syncing functionality, please see Advanced Setup.</p>"},{"location":"g002_data/#simple-setup","title":"Simple Setup","text":""},{"location":"g002_data/#getting-data-from-aws","title":"Getting Data from AWS","text":"<p>We store our data on AWS S3 Buckets. We have two buckets, one for G002 and one for G003. To get access to the buckets, you need to obtain credentials. Buckets are HIPAA compliant and are encrypted.</p>"},{"location":"g002_data/#obtaining-aws-credentials","title":"Obtaining AWS credentials.","text":"<p>To get AWS credentials, you can email Troy to get access.</p> <p>There are two scenarios for access.</p> <ol> <li> <p>You already have an AWS key. In that case, email us your IAM ARN and we will add you to the IAM group.</p> </li> <li> <p>You don't have an AWS account and need to be added to the SchiefLab group. In that case, you will receive an email with login instructions, your OTP (one time password) and your security credentials. The security credentials will be your AWS key and secret key and will be used to access the data programatically</p> </li> </ol>"},{"location":"g002_data/#aws-g002","title":"AWS G002","text":"<p>To get G002 data, we use AWS buckets. The bucket <code>S3URI</code> is <code>s3://iavig002westbucket/g002/</code>. The data is organized by sequencing, sorting and output. To get the data, you need the AWS CLI.</p> <p>To get AWS CLI, follow the instructions here.</p> <p>Once you get the AWS CLI, you need to configure it. Follow the instructions here.</p> <pre><code>$ aws configure\nAWS Access Key ID [None]: Secret key in email credentials\nAWS Secret Access Key [None]: Secret key in email credentials\nDefault region name [None]: us-west-2\nDefault output format [None]: json\n</code></pre> <p>Once you are configured, we can check if you have access to the S3 bucket.</p> <pre><code>$ aws s3 ls s3://iavig002westbucket/\nPRE g002/\n</code></pre> <p>G002</p> <p>You have access to the bucket if you are shown the <code>PRE g002/</code> output.</p>"},{"location":"g002_data/#aws-s3-copy-specific-files","title":"AWS S3 Copy Specific Files","text":"<p>Below is a way to only copy certain components of the AWS bucket</p> Sorting <pre><code>$ aws s3 cp --recursive  s3://iavig002westbucket/g002/G002/sorting/ buckets/g002/G002/sorting\n---&gt; 100%\n</code></pre> Sequencing <p>Get all sequencing files    <pre><code>$ aws s3 cp --recursive  s3://iavig002westbucket/g002/G002/sorting/ buckets/g002/G002/sequencing\n---&gt; 100%\n</code></pre> </p> <p>get the sequencing directory excluding large bcl and fastq files    <pre><code>$ aws s3 cp --recursive s3://iavig002westbucket/g002/G002/sequencing ./g002/G002/sequencing --exclude *working_directory/* --exclude *.fastq.gz --exclude *.tif --exclude *.cbcl --exclude *.imf1 --exclude *.filter --exclude *.bin --exclude *Logs/* --exclude *_stdout --exclude *_stderr --exclude *Autofocus/* --exclude *Intensities/*\n---&gt; 100%\n</code></pre> </p> Output <pre><code>$ aws s3 cp --recursive  s3://iavig002westbucket/g002/G002/output/ buckets/g002/G002/output\n---&gt; 100%\n</code></pre>"},{"location":"g002_data/#aws-s3-sync-all-files","title":"AWS S3 Sync All Files","text":"<pre><code>$ aws s3 sync --delete  s3://iavig002westbucket/ buckets/\n---&gt; 100%\n</code></pre> <p>Warning: Large File</p> <p>The entire bucket will likely be over 2 TB</p> <p>--delete</p> <p>The <code>--delete</code> flag will delete any files in the destination that are not in the source. This is useful for keeping the destination in sync with the source. If you don't want to delete files, remove the <code>--delete</code> flag.</p> <p>Sync</p> <p>The <code>sync</code> command can also be used on specific file subsets, e.g. sorting.</p>"},{"location":"g002_data/#advanced-setup","title":"Advanced Setup","text":"<p>For those users that need to mount Box or Globus, we have two sets of instructions below. The first is for a quick setup if you are using an AWS instance; otherwise, we recommend using the second set of instructions for a local machine.</p> <ul> <li>The 2 Available Options:</li> <li>AWS Instance Quick Setup</li> <li>Local Machine Setup</li> </ul>"},{"location":"g002_data/#aws-instance-setup","title":"AWS Instance Setup","text":"<p>For this to work, you must have all the following completed:</p> <ol> <li>You have a running AWS instance with a home directory for a user with sudo privileges</li> <li>You were invited to the G002 Box.</li> <li>You were invited to the G002 Globus collection.</li> <li>G00x is installed on your AWS instance. If not, follow the instructions here</li> </ol>"},{"location":"g002_data/#box-auto-sync","title":"Box Auto Sync","text":"<p>This could take 3+ hours, but it will be running in the background using systemd.</p> <pre><code>$ g00x g002 box setup\n## Click the link and sign into your Box account when prompted\n</code></pre> <p>To check on the status of the sync, run the following:.</p> <pre><code>$ g00x g002 box status\n</code></pre>"},{"location":"g002_data/#globus-auto-sync","title":"Globus Auto Sync","text":"<p>This could take 1+ hours, but it will be running in the background using systemd.</p> <pre><code>$ g00x g002 globus setup\n## Click the link and sign in to your Globus account when prompted\n</code></pre> <p>To check on the status of the sync, run the following.</p> <pre><code>$ g00x g002 globus status\n</code></pre> <p>You are done! Please skip the rest of this page regarding local machine setup.</p>"},{"location":"g002_data/#local-machine-setup","title":"Local Machine Setup","text":"<p>DO NOT DO IF YOU ALREADY COMPLETE THE AWS QUICK SETUP</p>"},{"location":"g002_data/#mounting-box","title":"Mounting Box","text":""},{"location":"g002_data/#rclone","title":"Rclone","text":"<p>To mount Box, we will use a utility called R clone. R clone is a command line utility that can be used to mount cloud storage. To install R clone, follow the instructions here.</p> <p>Once you install, you can run the following.</p> <pre><code>$ rclone config\n</code></pre> <p>It will ask you a few questions. I used the following answers.</p> <pre><code>n) new remote\nname &gt; box\nstorage &gt; 6\nclient_id &gt; (leave blank)\nclient_secret &gt; (leave blank)\nbox_config_file &gt; (leave blank)\nbox_sub_type &gt; 1\nEdit advanced config? (y/n) &gt; n\nUse auto config? (y/n) &gt; &lt;see below&gt;\n</code></pre> <p><code>use auto config</code> depends on whether you use a machine with a browser (like your personal computer). If you are on a server without access to a browser, hit <code>n</code> and you will be given a link to copy and paste into a browser.</p> <p>If you hit <code>n</code>, head over to a machine with rclone installed (e.g. brew install rclone) that has a browser and type.</p> <pre><code>$ rclone authorize box\n</code></pre> <p>That will take you to a login page. Just log in and hit authorise. Come back to the command line console, and you will see a code that looks like the following.</p> <pre><code>#Paste this code into the rclone configuration:\n&gt;result  {\"access_token\":\"LGOqxaTWf2Tzc6Na0\",\"token_type\":\"bearer\",\"refresh_token\":\"t8DBslxjlZ7JXiRBk5rqv1cVFN6O5BUcFEzzzFS2\",\"expiry\":\"2022-12-19T12:32:17.317533-06:00\"}\n</code></pre> <p>There you now have Box setup to mount! Check <code>~/.config/rclone/rclone.conf</code> to see the configuration and that the token is in there.</p>"},{"location":"g002_data/#mounting-box_1","title":"Mounting Box","text":"<p>To mount Box, you can use the following command</p> <pre><code>you can't mount this on fsx so put on /mnt/\n$ mkdir /mnt/box\n\nchange ownership\n$ sudo -R chown jwillis:jwillis /mnt/box\n\nmount with rclone\n$ rclone mount --daemon g002: /mnt/box\n</code></pre> <p>Now Box will be mounted to /mnt/Box</p> <p>Path must exist</p> <p>The /mnt/path/to/Box must exist. If it doesn't, you will get an error.</p>"},{"location":"g002_data/#mounting-globus","title":"Mounting Globus","text":"<p>To install globus, we need Globus Personal Connect. You can find the complete installation here</p> <p>Once you install, you can run the following.</p> <pre><code>$ /path/to/globus/install/globusconnectpersonal -start &amp;\n</code></pre>"},{"location":"g002_pipeline/","title":"10x pipeline","text":"<p>After you have a validated merged dataframe from validation, you can begin the 10X pipeline consisting of demultiplexing, vdj, and feature counting.</p> <p></p> <p>CellRanger 6.1</p> <p>The CellRanger version in this pipeline is 6.1</p>"},{"location":"g002_pipeline/#flow","title":"Flow","text":":material-console-line: Command Line Usage :material-api: Python <p>The following will analyze the flow path and output a dataframe that will be used in analysis. It computes each count of each gate that are useful in frequency analysis.</p> <p> <pre><code>$ g00x g002 pipeline flow -o g002/G002/output/flow /path/to/flow\n</code></pre> </p> <pre><code>import pandas as pd\nfrom g00x.data import Data\nfrom g00x.flow.flow import parse_flow_data\nfrom pathlib import Path\n\ndata = ctx.obj[\"data\"]\nfolder = 'path/to/flow'\nflow_data = parse_flow_data(data, folder)\nout = Path(out)\noutput_feather = Path(out.parent / (out.stem + \".feather\"))\noutput_csv = Path(out.parent / (out.stem + \".csv\"))\n</code></pre> <p>Here is what the flow dataframe will look like.</p> run_purpose run_date sort_id ptid group weeks visit_id probe_set sample_type sort_software_dv sort_file_type sample_tube gate phenotype value_type extention file_path file_subset value branch easy_name notes sort_pool hashtag 119 PreS 2022-08-25 S6C G002831 2 -5 V091 eODGT8 PBMC DV Summary T1 P11 IgD+/Antigen++ count .csv ['g002/G002/sorting/G002/Prescreens/Prescreen_RunDate220825_UploadDate221021/PopulationSummaryFilesFromDV/PreS_220825_S6C_G002831_V091_eODGT8_PBMC_DV_Summary_T1_a.csv'] ['a'] 50 IgD+ antigen_pos_igd_pos_b_cells nan 2461 PreS 2022-11-04 S6C G002136 2 8 V200 eODGT8 PBMC DV Summary T1 P13 IgD+/KO- count .csv ['g002/G002/sorting/G002/Prescreens/Prescreen_RunDate221104_UploadDate221129/PopulationSummaryFilesFromDV/PreS_221104_S6C_G002136_V200_eODGT8_PBMC_DV_Summary_T1_a.csv'] ['a'] 190682 IgD+ nan 2754 PreS 2022-11-04 S6C G002947 2 8 V200 Cg28v2 PBMC DV Summary T1 P31 IgG-IgM-/IgA+/KO- count .csv ['g002/G002/sorting/G002/Prescreens/Prescreen_RunDate221104_UploadDate221129/PopulationSummaryFilesFromDV/PreS_221104_S6C_G002947_V200_Cg28v2_PBMC_DV_Summary_T1_a.csv'] ['a'] 10498 IgA+ nan 4485 Sort 2022-10-25 S6C G002831 2 4 V160 eODGT8 PBMC DV Summary T1 P27 IgG-IgM-IgD- count .csv ['g002/G002/sorting/G002/Sorts/Sort_RunDate221025_UploadDate221101/ClinicalSamples/PopulationSummaryFilesFromDV/Sort_221025_S6C_G002831_V160_eODGT8_PBMC_HT02_DV_Summary_T1_P03_a.csv'] ['a'] 100696 nan P03 HT02 2343 PreS 2022-11-04 S6C G002136 2 -5 V091 eODGT8 PBMC DV Summary T1 P12 IgD+/Antigen++/KO- count .csv ['g002/G002/sorting/G002/Prescreens/Prescreen_RunDate221104_UploadDate221129/PopulationSummaryFilesFromDV/PreS_221104_S6C_G002136_V091_eODGT8_PBMC_DV_Summary_T1_a.csv'] ['a'] 47 IgD+ epitope_pos_igd_pos_b_cells_rev nan"},{"location":"g002_pipeline/#demultiplexing","title":"Demultiplexing","text":"<p>The input to the demultiplexing part of the pipeline will be the sequencing and flow file paths</p> :material-console-line: Command Line Usage :material-api: Python <p> <pre><code>$ g00x g002 pipeline demultiplex -o g002/G002/output/demultiplex -f /path/to/flow -s /path/to/sequencing\n</code></pre> </p> <pre><code>import pandas as pd\nfrom g00x.data import Data\nfrom g00x.sequencing.tenX import run_demultiplex\n\nflow_path = \"path/to/flow\"\nsequencing_path = \"path/to/sequencing\"\ndata = Data()\nmerged_dataframe: pd.DataFrame = merge_flow_and_sequencing(data, flow_path, sequencing_path)  # type: ignore\ndemultiplex_df = run_demultiplex(data, merged_dataframe, out, overwrite)\ndemultiplex_df.to_csv(\"demultiplex.csv\")\ndemultiplex_df.to_csv(\"demultiplex.feather\")\n</code></pre> <p>The demulitplex algorithm will add the following fields in demultiplex output</p> Column Definition vdj_run_dir The full path to the vdj run directory, e.g. the Illumina directory cso_run_dir The full path to the cso run directory, e.g. the Illumina directory vdj_sample_name The unique vdj sample name given to each row cso_sample_name The unique cso sample name given to each row vdj_fastq_dir The full path to the vdj fastq directory cso_fastq_dir The full path to the cso fastq directory <p>An example of a demultiplexing output dataframe is found below.</p> ptid group weeks visit_id probe_set sample_type run_date sort_pool hashtag run_dir_path pool_number sorted_date vdj_sequencing_replicate cso_sequencing_replicate vdj_lirary_replicate cso_library_replicate bio_replicate vdj_index feature_index vdj_run_id cso_run_id vdj_run_dir_path cso_run_dir_path vdj_fastq_dir vdj_sample_name cso_fastq_dir cso_sample_name 0 G002516 1 -5 V091 eODGT8 PBMC 2022-09-27 P01 HT01 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002 P01 2022-09-27 0 0 0 0 0 SI-TT-D6 SI-TN-D6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path vdj-SI-TT-D6 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path cso-SI-TN-D6 1 G002516 1 4 V160 eODGT8 PBMC 2022-09-27 P01 HT02 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002 P01 2022-09-27 0 0 0 0 0 SI-TT-D6 SI-TN-D6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path vdj-SI-TT-D6 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path cso-SI-TN-D6"},{"location":"g002_pipeline/#vdj","title":"VDJ","text":"<p>The output of demultiplexing pipeline will be used as input, see the pipeline</p> :material-console-line: Command Line Usage :material-api: Python <p>The following will run the VDJ pipeline from the demultiplex dataframe and output the vdj.feather inside the output folder.</p> <p> <pre><code>Run it from demultiplexed dataframe\n$ g00x g002 pipeline vdj -o g002/G002/output/vdj -d output/demultiplexed.feather\n</code></pre> </p> <p>You can run the same with the following Python code.</p> <pre><code>from g00x.sequencing.tenX import run_vdj\nfrom g00x.data import Data\n\ndata = Data()\ndemultiplex_dataframe = pd.read_feather(demultiplex_dataframe_path)\nrun_vdj(data, demultiplex_dataframe, out)\n</code></pre> <p>The output vdj dataframe will only contain one additional field</p> Column Definition vdj_output The full path to the vdj output folder"},{"location":"g002_pipeline/#cso","title":"CSO","text":"<p>This CSO pipeline will run the cellranger count part and output a feature matrix. It also uses the demultiplex.feather as input.</p> :material-console-line: Command Line Usage :material-api: Python <p>The following will run the CSO pipeline from the demultiplex dataframe and output cso.feather inside the output folder.</p> <p> <pre><code>Run it from demultiplexed dataframe\n$ g00x g002 pipeline cso -o g002/G002/output/cso -d output/demultiplexed.feather\n</code></pre> </p> <p>You can run the same with the following Python code.</p> <pre><code>from g00x.sequencing.tenX import run_cso\nfrom g00x.data import Data\n\ndata = Data()\ndemultiplex_dataframe = pd.read_feather(demultiplex_dataframe_path)\nrun_cso(data, demultiplex_dataframe, out)\n</code></pre> <p>The output CSO dataframe will only contain one additional field</p> Column Definition cso_output The full path to the cso output folder"},{"location":"g002_pipeline/#airr","title":"AIRR","text":"<p>The output of the VDJ and CSO can now be combined to get a final sequencing dataframe. This is the final sequencing dataframe that will be used for the analysis.</p> <p>The AIRR protocol does the following.</p> <p>It will...</p> <ol> <li>Run SADIE AIRR on the VDJ contigs to get a formalized AIRR dataframe.</li> <li>Analyze the feature barcodes and assign cellids to the correct participant.</li> <li>Add the PubIDs to the AIRR dataframe.</li> <li>Run mutational analysis</li> <li>Run iGL assignment to all sequences</li> <li>Determine if sequence is VRC01 class</li> <li>Add mutational sets (find what mutations are VRC01-like)</li> <li>Cluster sequences</li> <li>Determine isotype</li> </ol> :material-console-line: Command Line Usage :material-api: Python <p>The following will run the AIRR pipeline from the VDJ and CSO dataframes and output airr.feather inside of the output folder.</p> <p> <pre><code>Run it from VDJ and CSO dataframes\n$ g00x g002 pipeline airr -o g002/G002/output/airr -v output/vdj.feather -c output/cso.feather\n</code></pre> </p> <p>You can run the same with the following Python code.</p> <pre><code>from g00x.data import Data\nfrom g00x.sequencing.airr import run_airr\n\nvdj_out = 'output/vdj.feather'\ncso_out = 'output/cso.feather'\ndata = Data()\nvdj_dataframe = pd.read_feather(vdj_out)\ncso_dataframe = pd.read_feather(cso_out)\noutput_df = run_airr(data, vdj_dataframe, cso_dataframe, out, overwrite)\n</code></pre> <p>An output dataframe will take the following:</p> cellid pubID ptid group weeks visit_id probe_set sample_type run_date sort_pool hashtag run_dir_path pool_number sorted_date vdj_sequencing_replicate cso_sequencing_replicate vdj_lirary_replicate cso_library_replicate bio_replicate vdj_index feature_index vdj_run_id cso_run_id vdj_run_dir_path cso_run_dir_path vdj_fastq_dir vdj_sample_name cso_fastq_dir cso_sample_name vdj_output cso_output sadie_airr_path paired_sadie_airr_path cellhash sequence_id_heavy sequence_heavy reference_name_heavy locus_heavy stop_codon_heavy vj_in_frame_heavy v_frameshift_heavy productive_heavy rev_comp_heavy complete_vdj_heavy v_call_top_heavy v_call_heavy d_call_top_heavy d_call_heavy j_call_top_heavy j_call_heavy c_call_heavy sequence_alignment_heavy germline_alignment_heavy sequence_alignment_aa_heavy germline_alignment_aa_heavy v_alignment_start_heavy v_alignment_end_heavy d_alignment_start_heavy d_alignment_end_heavy j_alignment_start_heavy j_alignment_end_heavy c_alignment_start_heavy c_alignment_end_heavy v_sequence_alignment_heavy v_sequence_alignment_aa_heavy v_germline_alignment_heavy v_germline_alignment_aa_heavy d_sequence_alignment_heavy d_sequence_alignment_aa_heavy d_germline_alignment_heavy d_germline_alignment_aa_heavy j_sequence_alignment_heavy j_sequence_alignment_aa_heavy j_germline_alignment_heavy j_germline_alignment_aa_heavy c_sequence_alignment_heavy c_sequence_alignment_aa_heavy c_germline_alignment_heavy c_germline_alignment_aa_heavy fwr1_heavy fwr1_aa_heavy cdr1_heavy cdr1_aa_heavy fwr2_heavy fwr2_aa_heavy cdr2_heavy cdr2_aa_heavy fwr3_heavy fwr3_aa_heavy fwr4_heavy fwr4_aa_heavy cdr3_heavy cdr3_aa_heavy junction_heavy junction_length_heavy junction_aa_heavy junction_aa_length_heavy v_score_heavy d_score_heavy j_score_heavy c_score_heavy v_cigar_heavy d_cigar_heavy j_cigar_heavy c_cigar_heavy v_support_heavy d_support_heavy j_support_heavy c_support_heavy v_identity_heavy d_identity_heavy j_identity_heavy c_identity_heavy v_sequence_start_heavy v_sequence_end_heavy v_germline_start_heavy v_germline_end_heavy d_sequence_start_heavy d_sequence_end_heavy d_germline_start_heavy d_germline_end_heavy j_sequence_start_heavy j_sequence_end_heavy j_germline_start_heavy j_germline_end_heavy c_sequence_start_heavy c_sequence_end_heavy c_germline_start_heavy c_germline_end_heavy fwr1_start_heavy fwr1_end_heavy cdr1_start_heavy cdr1_end_heavy fwr2_start_heavy fwr2_end_heavy cdr2_start_heavy cdr2_end_heavy fwr3_start_heavy fwr3_end_heavy fwr4_start_heavy fwr4_end_heavy cdr3_start_heavy cdr3_end_heavy np1_heavy np1_length_heavy np2_heavy np2_length_heavy liable_heavy vdj_nt_heavy vdj_aa_heavy v_mutation_heavy v_mutation_aa_heavy d_mutation_heavy d_mutation_aa_heavy j_mutation_heavy j_mutation_aa_heavy v_penalty_heavy d_penalty_heavy j_penalty_heavy germline_alignment_aa_corrected_heavy v_germline_alignment_aa_corrected_heavy sequence_id_light sequence_light reference_name_light locus_light stop_codon_light vj_in_frame_light v_frameshift_light productive_light rev_comp_light complete_vdj_light v_call_top_light v_call_light d_call_top_light d_call_light j_call_top_light j_call_light c_call_light sequence_alignment_light germline_alignment_light sequence_alignment_aa_light germline_alignment_aa_light v_alignment_start_light v_alignment_end_light d_alignment_start_light d_alignment_end_light j_alignment_start_light j_alignment_end_light c_alignment_start_light c_alignment_end_light v_sequence_alignment_light v_sequence_alignment_aa_light v_germline_alignment_light v_germline_alignment_aa_light d_sequence_alignment_light d_sequence_alignment_aa_light d_germline_alignment_light d_germline_alignment_aa_light j_sequence_alignment_light j_sequence_alignment_aa_light j_germline_alignment_light j_germline_alignment_aa_light c_sequence_alignment_light c_sequence_alignment_aa_light c_germline_alignment_light c_germline_alignment_aa_light fwr1_light fwr1_aa_light cdr1_light cdr1_aa_light fwr2_light fwr2_aa_light cdr2_light cdr2_aa_light fwr3_light fwr3_aa_light fwr4_light fwr4_aa_light cdr3_light cdr3_aa_light junction_light junction_length_light junction_aa_light junction_aa_length_light v_score_light d_score_light j_score_light c_score_light v_cigar_light d_cigar_light j_cigar_light c_cigar_light v_support_light d_support_light j_support_light c_support_light v_identity_light d_identity_light j_identity_light c_identity_light v_sequence_start_light v_sequence_end_light v_germline_start_light v_germline_end_light d_sequence_start_light d_sequence_end_light d_germline_start_light d_germline_end_light j_sequence_start_light j_sequence_end_light j_germline_start_light j_germline_end_light c_sequence_start_light c_sequence_end_light c_germline_start_light c_germline_end_light fwr1_start_light fwr1_end_light cdr1_start_light cdr1_end_light fwr2_start_light fwr2_end_light cdr2_start_light cdr2_end_light fwr3_start_light fwr3_end_light fwr4_start_light fwr4_end_light cdr3_start_light cdr3_end_light np1_light np1_length_light np2_light np2_length_light liable_light vdj_nt_light vdj_aa_light v_mutation_light v_mutation_aa_light d_mutation_light d_mutation_aa_light j_mutation_light j_mutation_aa_light v_penalty_light d_penalty_light j_penalty_light germline_alignment_aa_corrected_light v_germline_alignment_aa_corrected_light HTO iGL_aa_heavy iGL_aa_light mutations_heavy mutations_light 100bW is_vrc01_class cottrell_focused_v_common_heavy_positive cottrell_focused_v_common_heavy_negative cottrell_focused_v_common_score hcdr3_len lcdr3_len top_c_call cluster is_centroid 7268 G002-630_2_8_eODGT8_P02_GTCACAAGTTGATTGC-1 G002-630 G002630 2 8 V200 eODGT8 PBMC 2022-09-30 P02 HT08 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002 P02 2022-09-30 0 0 0 0 0 SI-TT-H6 SI-TN-H6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path vdj-SI-TT-H6 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path cso-SI-TN-H6 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/vdj/vdj_output_0004 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/cso/cso_output_0004 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/vdj/vdj_output_0004/outs/sadie_airr.feather /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002/working_directory/vdj/vdj_output_0004/outs/paired_sadie_airr.feather GTCACAAGTTGATTGC-1 GTCACAAGTTGATTGC-1_contig_2 GAGAGCATCACCCAGCAACCACATCTGTCCTCTAGAGAATCCCCTGAGAGCTCCGTTCCTCACCATGGACTGGACCTGGAGGATTCTCTTCTTGGTGGCAGCAGCCACAGGAGCCCACTCCCAGGTGCAGCTGGTGCAGTCTGGGGCTGAGGTGAAGAAGCCTGGGGCCTCAGTGAAGGTCTCCTGCAAGGCTTCTGGATACACCTTCACCGGCTACTATATGCACTGGGTGCGACAGGCCCCTGGACAAGGGCTTGAGTGGATGGGATGCATCAACCCTAACAGTGGTGGCACAAACTATGCACAGAAGTTTCAGGGCAGGGTCACCATGACCAGGGACACGTCCATCAGCACAGCCTACATGGAGCTGAGCAGGCTGAGATCTGACGACACGGCCGTATATTATTGTGCGAGAGATCTGTATGGTGGGAGCTACTCGGTTGACTACTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAGCCTCCACCAAGGGCCCATCGGTCTTCCCCCTGGCACCCTCCTCCAAGAGCACCTCTGGGGGCACAGC human IGH False True False True False True IGHV1-2*02 IGHV1-2*02 IGHD1-26*01 IGHD1-26*01 IGHJ4*02 IGHJ4*02 IGHG1*01 CAGGTGCAGCTGGTGCAGTCTGGGGCTGAGGTGAAGAAGCCTGGGGCCTCAGTGAAGGTCTCCTGCAAGGCTTCTGGATACACCTTCACCGGCTACTATATGCACTGGGTGCGACAGGCCCCTGGACAAGGGCTTGAGTGGATGGGATGCATCAACCCTAACAGTGGTGGCACAAACTATGCACAGAAGTTTCAGGGCAGGGTCACCATGACCAGGGACACGTCCATCAGCACAGCCTACATGGAGCTGAGCAGGCTGAGATCTGACGACACGGCCGTATATTATTGTGCGAGAGATCTGTATGGTGGGAGCTACTCGGTTGACTACTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAG CAGGTGCAGCTGGTGCAGTCTGGGGCTGAGGTGAAGAAGCCTGGGGCCTCAGTGAAGGTCTCCTGCAAGGCTTCTGGATACACCTTCACCGGCTACTATATGCACTGGGTGCGACAGGCCCCTGGACAAGGGCTTGAGTGGATGGGATGGATCAACCCTAACAGTGGTGGCACAAACTATGCACAGAAGTTTCAGGGCAGGGTCACCATGACCAGGGACACGTCCATCAGCACAGCCTACATGGAGCTGAGCAGGCTGAGATCTGACGACACGGCCGTGTATTACTGTGCGAGAGANNNGTATAGTGGGAGCTACTNNNTTGACTACTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAG QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLEWMGCINPNSGGTNYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCARDLYGGSYSVDYWGQGTLVTVSS QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLEWMGWINPNSGGTNYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCARXXYSGSYXXDYWGQGTLVTVSS 1 296 300 316 320 361 361 428 CAGGTGCAGCTGGTGCAGTCTGGGGCTGAGGTGAAGAAGCCTGGGGCCTCAGTGAAGGTCTCCTGCAAGGCTTCTGGATACACCTTCACCGGCTACTATATGCACTGGGTGCGACAGGCCCCTGGACAAGGGCTTGAGTGGATGGGATGCATCAACCCTAACAGTGGTGGCACAAACTATGCACAGAAGTTTCAGGGCAGGGTCACCATGACCAGGGACACGTCCATCAGCACAGCCTACATGGAGCTGAGCAGGCTGAGATCTGACGACACGGCCGTATATTATTGTGCGAGAGA QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLEWMGCINPNSGGTNYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCAR CAGGTGCAGCTGGTGCAGTCTGGGGCTGAGGTGAAGAAGCCTGGGGCCTCAGTGAAGGTCTCCTGCAAGGCTTCTGGATACACCTTCACCGGCTACTATATGCACTGGGTGCGACAGGCCCCTGGACAAGGGCTTGAGTGGATGGGATGGATCAACCCTAACAGTGGTGGCACAAACTATGCACAGAAGTTTCAGGGCAGGGTCACCATGACCAGGGACACGTCCATCAGCACAGCCTACATGGAGCTGAGCAGGCTGAGATCTGACGACACGGCCGTGTATTACTGTGCGAGAGA QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLEWMGWINPNSGGTNYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCAR GTATGGTGGGAGCTACT YGGSY GTATAGTGGGAGCTACT YSGSY TTGACTACTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAG DYWGQGTLVTVSS TTGACTACTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAG DYWGQGTLVTVSS GCCTCCACCAAGGGCCCATCGGTCTTCCCCCTGGCACCCTCCTCCAAGAGCACCTCTGGGGGCACAGC ASTKGPSVFPLAPSSKSTSGGTA GCCTCCACCAAGGGCCCATCGGTCTTCCCCCTGGCACCCTCCTCCAAGAGCACCTCTGGGGGCACAGC ASTKGPSVFPLAPSSKSTSGGTA CAGGTGCAGCTGGTGCAGTCTGGGGCTGAGGTGAAGAAGCCTGGGGCCTCAGTGAAGGTCTCCTGCAAGGCTTCT QVQLVQSGAEVKKPGASVKVSCKAS GGATACACCTTCACCGGCTACTAT GYTFTGYY ATGCACTGGGTGCGACAGGCCCCTGGACAAGGGCTTGAGTGGATGGGATGC MHWVRQAPGQGLEWMGC ATCAACCCTAACAGTGGTGGCACA INPNSGGT AACTATGCACAGAAGTTTCAGGGCAGGGTCACCATGACCAGGGACACGTCCATCAGCACAGCCTACATGGAGCTGAGCAGGCTGAGATCTGACGACACGGCCGTATATTATTGT NYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYC TGGGGCCAGGGAACCCTGGTCACCGTCTCCTCA WGQGTLVTVSS GCGAGAGATCTGTATGGTGGGAGCTACTCGGTTGACTAC ARDLYGGSYSVDY TGTGCGAGAGATCTGTATGGTGGGAGCTACTCGGTTGACTACTGG 45 CARDLYGGSYSVDYW 15 453.689 25.359 68.153 135.293 121S296M132S 420S1N17M112S2N 440S6N42M67S 481S68M226N 1.482e-129 0.00309 1.321e-15 4.201e-35 0.98986 0.94118 1 100 122 417 1 296 421 437 2 18 441 482 7 48 482 549 1 68 122 196 197 220 221 271 272 295 296 409 449 481 410 448 TCT 3 CGG 3 False CAGGTGCAGCTGGTGCAGTCTGGGGCTGAGGTGAAGAAGCCTGGGGCCTCAGTGAAGGTCTCCTGCAAGGCTTCTGGATACACCTTCACCGGCTACTATATGCACTGGGTGCGACAGGCCCCTGGACAAGGGCTTGAGTGGATGGGATGCATCAACCCTAACAGTGGTGGCACAAACTATGCACAGAAGTTTCAGGGCAGGGTCACCATGACCAGGGACACGTCCATCAGCACAGCCTACATGGAGCTGAGCAGGCTGAGATCTGACGACACGGCCGTATATTATTGTGCGAGAGATCTGTATGGTGGGAGCTACTCGGTTGACTACTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCA QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLEWMGCINPNSGGTNYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCARDLYGGSYSVDYWGQGTLVTVSS 0.01014 0.0102041 0.05882 0.2 0 0 -1 -1 -1 False False GTCACAAGTTGATTGC-1_contig_1 AGGAGTCAGACCCAGTCAGGACACAGCATGGACATGAGGGTCCCCGCTCAGCTCCTGGGGCTCCTGCTGCTCTGGTTCCCAGGTTCCAGATGCGACATCCAGATGACCCAGTCTCCATCTTCCGTGTCTGCATCTGTAGGAGACAGAGTCACCATCACTTGTCGGGCGAGTCAGGGTATTAGCAGCTGGTTAGCCTGGTATCAGCAGAAACCAGGGAAAGCCCCTAAACTCCTGATCTATGCTGCATCCAGTTTGCAAAGTGGGGTCCCATCAAGGTTCAGCGGCAGTGCATCTGGGACAGATTTCACTCTCACCATCAGCAGCCTGCAGCCTGAAGATTTTGCAACTTACTATTGTCAACAGGCTAACAGTTTCCCCCTCACTTTCGGCGGAGGGACCAAGGTGGAGATCAAACGAACTGTGGCTGCACCATCTGTCTTCATCTTCCCGCCATCTGATGAGCAGTTGAAATCTGGAACTGCCTCTGTTGTGTGCCTGCTGAATAACTTCTATCCCAGAGAGGCCAAAGTACAGTGGAAGGTGGATAACGC human IGK False True False True False True IGKV1-12*01 IGKV1-1201,IGKV1-1202 IGKJ4*01 IGKJ4*01 IGKC*01 GACATCCAGATGACCCAGTCTCCATCTTCCGTGTCTGCATCTGTAGGAGACAGAGTCACCATCACTTGTCGGGCGAGTCAGGGTATTAGCAGCTGGTTAGCCTGGTATCAGCAGAAACCAGGGAAAGCCCCTAAACTCCTGATCTATGCTGCATCCAGTTTGCAAAGTGGGGTCCCATCAAGGTTCAGCGGCAGTGCATCTGGGACAGATTTCACTCTCACCATCAGCAGCCTGCAGCCTGAAGATTTTGCAACTTACTATTGTCAACAGGCTAACAGTTTCCCCCTCACTTTCGGCGGAGGGACCAAGGTGGAGATCAAAC GACATCCAGATGACCCAGTCTCCATCTTCCGTGTCTGCATCTGTAGGAGACAGAGTCACCATCACTTGTCGGGCGAGTCAGGGTATTAGCAGCTGGTTAGCCTGGTATCAGCAGAAACCAGGGAAAGCCCCTAAGCTCCTGATCTATGCTGCATCCAGTTTGCAAAGTGGGGTCCCATCAAGGTTCAGCGGCAGTGGATCTGGGACAGATTTCACTCTCACCATCAGCAGCCTGCAGCCTGAAGATTTTGCAACTTACTATTGTCAACAGGCTAACAGTTTCCCNCTCACTTTCGGCGGAGGGACCAAGGTGGAGATCAAAC DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSASGTDFTLTISSLQPEDFATYYCQQANSFPLTFGGGTKVEIK DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQANSFPLTFGGGTKVEIK 1 284 286 322 322 458 GACATCCAGATGACCCAGTCTCCATCTTCCGTGTCTGCATCTGTAGGAGACAGAGTCACCATCACTTGTCGGGCGAGTCAGGGTATTAGCAGCTGGTTAGCCTGGTATCAGCAGAAACCAGGGAAAGCCCCTAAACTCCTGATCTATGCTGCATCCAGTTTGCAAAGTGGGGTCCCATCAAGGTTCAGCGGCAGTGCATCTGGGACAGATTTCACTCTCACCATCAGCAGCCTGCAGCCTGAAGATTTTGCAACTTACTATTGTCAACAGGCTAACAGTTTCCC DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSASGTDFTLTISSLQPEDFATYYCQQANSFP GACATCCAGATGACCCAGTCTCCATCTTCCGTGTCTGCATCTGTAGGAGACAGAGTCACCATCACTTGTCGGGCGAGTCAGGGTATTAGCAGCTGGTTAGCCTGGTATCAGCAGAAACCAGGGAAAGCCCCTAAGCTCCTGATCTATGCTGCATCCAGTTTGCAAAGTGGGGTCCCATCAAGGTTCAGCGGCAGTGGATCTGGGACAGATTTCACTCTCACCATCAGCAGCCTGCAGCCTGAAGATTTTGCAACTTACTATTGTCAACAGGCTAACAGTTTCCC DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQANSFP CTCACTTTCGGCGGAGGGACCAAGGTGGAGATCAAAC LTFGGGTKVEIK CTCACTTTCGGCGGAGGGACCAAGGTGGAGATCAAAC LTFGGGTKVEIK CGAACTGTGGCTGCACCATCTGTCTTCATCTTCCCGCCATCTGATGAGCAGTTGAAATCTGGAACTGCCTCTGTTGTGTGCCTGCTGAATAACTTCTATCCCAGAGAGGCCAAAGTACAGTGGAAGGTGGATAACGC RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA CGAACTGTGGCTGCACCATCTGTCTTCATCTTCCCGCCATCTGATGAGCAGTTGAAATCTGGAACTGCCTCTGTTGTGTGCCTGCTGAATAACTTCTATCCCAGAGAGGCCAAAGTACAGTGGAAGGTGGATAACGC RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA GACATCCAGATGACCCAGTCTCCATCTTCCGTGTCTGCATCTGTAGGAGACAGAGTCACCATCACTTGTCGGGCGAGT DIQMTQSPSSVSASVGDRVTITCRAS CAGGGTATTAGCAGCTGG QGISSW TTAGCCTGGTATCAGCAGAAACCAGGGAAAGCCCCTAAACTCCTGATCTAT LAWYQQKPGKAPKLLIY GCTGCATCC AAS AGTTTGCAAAGTGGGGTCCCATCAAGGTTCAGCGGCAGTGCATCTGGGACAGATTTCACTCTCACCATCAGCAGCCTGCAGCCTGAAGATTTTGCAACTTACTATTGT SLQSGVPSRFSGSASGTDFTLTISSLQPEDFATYYC TTCGGCGGAGGGACCAAGGTGGAGATCAAA FGGGTKVEIK CAACAGGCTAACAGTTTCCCCCTCACT QQANSFPLT TGTCAACAGGCTAACAGTTTCCCCCTCACTTTC 33 CQQANSFPLTF 11 438.107 nan 60.229 272.075 93S284M174S3N 378S1N37M136S 414S137M184N 7.292e-125 nan 3.221e-13 2.814e-76 0.99296 nan 1 100 94 377 1 284 379 415 2 38 415 551 1 137 94 171 172 189 190 240 241 249 250 357 385 414 358 384 C 1 False GACATCCAGATGACCCAGTCTCCATCTTCCGTGTCTGCATCTGTAGGAGACAGAGTCACCATCACTTGTCGGGCGAGTCAGGGTATTAGCAGCTGGTTAGCCTGGTATCAGCAGAAACCAGGGAAAGCCCCTAAACTCCTGATCTATGCTGCATCCAGTTTGCAAAGTGGGGTCCCATCAAGGTTCAGCGGCAGTGCATCTGGGACAGATTTCACTCTCACCATCAGCAGCCTGCAGCCTGAAGATTTTGCAACTTACTATTGTCAACAGGCTAACAGTTTCCCCCTCACTTTCGGCGGAGGGACCAAGGTGGAGATCAAA DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSASGTDFTLTISSLQPEDFATYYCQQANSFPLTFGGGTKVEIK 0.00704002 0.0105263 nan nan 0 0 -1 -1 -1 False False HT08 QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLEWMGWINPNSGGTNYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCARDLYSGSYSVDYWGQGTLVTVSS DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQANSFPLTFGGGTKVEIK ['W50C' 'S98G'] ['G66A'] False False [] ['50'] -1 13 9 IGHG G002630_False_IGHG_320 True 10901 G002-341_2_4_eODGT8_P02_CCTAAAGGTCAAACTC-1 G002-341 G002341 2 4 V160 eODGT8 PBMC 2022-10-07 P02 HT07 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003 P02 2022-10-07 0 0 0 0 0 SI-TT-H5 SI-TN-C7 221019_VH00497_32_AAANGGVM5 221019_VH00497_32_AAANGGVM5 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003/221019_VH00497_32_AAANGGVM5 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003/221019_VH00497_32_AAANGGVM5 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003/working_directory/demultiplexed/d1191380460aa54876be7325a32a84c7/outs/fastq_path vdj-SI-TT-H5 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003/working_directory/demultiplexed/d1191380460aa54876be7325a32a84c7/outs/fastq_path cso-SI-TN-C7 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003/working_directory/vdj/vdj_output_0007 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003/working_directory/cso/cso_output_0007 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003/working_directory/vdj/vdj_output_0007/outs/sadie_airr.feather /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0003/working_directory/vdj/vdj_output_0007/outs/paired_sadie_airr.feather CCTAAAGGTCAAACTC-1 CCTAAAGGTCAAACTC-1_contig_1 AGATCTCAGAGAGGAGCCTTAGCCCTGGACTCCAAGGCCTTTCCACTTGGTGATCAGCACTGAGCACAGAGGACTCACCATGGAGTTGGGGCTGAGCTGGGTTTTCCTTGTTGCTATTTTAGAAGGTGTCCAGTGTGAGGTGCAGCTGGTGGAGTCTGGGGGAGGCTTGGTCCAGCCTGGGGGGTCCCTGAGACTCTCCTGTGCAGCCTCTGGATTCACCTTTAGTAGCTATTGGATGAGCTGGGTCCGCCAGGCTCCAGGGAAAGGGCTGGAGTGGGTGGCCAACATAAAGCAAGATGGAAGTGAGAAATACTATGTGGACTCTGTGAAGGGCCGATTCACCATCTCCAGAGACAACGCCAAGAACTCACTGTATCTGCAAATGAACAGCCTGAGAGCCGAGGACACGGCTGTGTATTACTGTGCGAGGGATTGGGTGGAAGGGCCCTGGTTCGACCCCTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAGCCTCCACCAAGGGCCCATCGGTCTTCCCCCTGGCACCCTCCTCCAAGAGCACCTCTGGGGGCACAGCGGCCCTGGGCTGCCTGGTCAAGGACTACTTCCCCGAACCGGTGACGGTGTCGTGGAACTCAGGCGCCCTGACCAGCGGCGTGCACACCTTCCCGGCTGTCCTACAGTCCTCAGGA human IGH False True False True False True IGHV3-7*04 IGHV3-7*04 IGHD2-15*01 IGHD2-15*01 IGHJ5*02 IGHJ5*02 IGHG1*01 GAGGTGCAGCTGGTGGAGTCTGGGGGAGGCTTGGTCCAGCCTGGGGGGTCCCTGAGACTCTCCTGTGCAGCCTCTGGATTCACCTTTAGTAGCTATTGGATGAGCTGGGTCCGCCAGGCTCCAGGGAAAGGGCTGGAGTGGGTGGCCAACATAAAGCAAGATGGAAGTGAGAAATACTATGTGGACTCTGTGAAGGGCCGATTCACCATCTCCAGAGACAACGCCAAGAACTCACTGTATCTGCAAATGAACAGCCTGAGAGCCGAGGACACGGCTGTGTATTACTGTGCGAGGGATTGGGTGGAAGGGCCCTGGTTCGACCCCTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAG GAGGTGCAGCTGGTGGAGTCTGGGGGAGGCTTGGTCCAGCCTGGGGGGTCCCTGAGACTCTCCTGTGCAGCCTCTGGATTCACCTTTAGTAGCTATTGGATGAGCTGGGTCCGCCAGGCTCCAGGGAAAGGGCTGGAGTGGGTGGCCAACATAAAGCAAGATGGAAGTGAGAAATACTATGTGGACTCTGTGAAGGGCCGATTCACCATCTCCAGAGACAACGCCAAGAACTCACTGTATCTGCAAATGAACAGCCTGAGAGCCGAGGACACGGCTGTGTATTACTGTGCGAGGGANNNGGTGGTAGNNNNCTGGTTCGACCCCTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAG EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLEWVANIKQDGSEKYYVDSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCARDWVEGPWFDPWGQGTLVTVSS EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLEWVANIKQDGSEKYYVDSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCARXXVVXXWFDPWGQGTLVTVSS 1 296 300 307 312 358 358 540 GAGGTGCAGCTGGTGGAGTCTGGGGGAGGCTTGGTCCAGCCTGGGGGGTCCCTGAGACTCTCCTGTGCAGCCTCTGGATTCACCTTTAGTAGCTATTGGATGAGCTGGGTCCGCCAGGCTCCAGGGAAAGGGCTGGAGTGGGTGGCCAACATAAAGCAAGATGGAAGTGAGAAATACTATGTGGACTCTGTGAAGGGCCGATTCACCATCTCCAGAGACAACGCCAAGAACTCACTGTATCTGCAAATGAACAGCCTGAGAGCCGAGGACACGGCTGTGTATTACTGTGCGAGGGA EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLEWVANIKQDGSEKYYVDSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCAR GAGGTGCAGCTGGTGGAGTCTGGGGGAGGCTTGGTCCAGCCTGGGGGGTCCCTGAGACTCTCCTGTGCAGCCTCTGGATTCACCTTTAGTAGCTATTGGATGAGCTGGGTCCGCCAGGCTCCAGGGAAAGGGCTGGAGTGGGTGGCCAACATAAAGCAAGATGGAAGTGAGAAATACTATGTGGACTCTGTGAAGGGCCGATTCACCATCTCCAGAGACAACGCCAAGAACTCACTGTATCTGCAAATGAACAGCCTGAGAGCCGAGGACACGGCTGTGTATTACTGTGCGAGGGA EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLEWVANIKQDGSEKYYVDSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCAR GGTGGAAG VE GGTGGTAG VV CTGGTTCGACCCCTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAG WFDPWGQGTLVTVSS CTGGTTCGACCCCTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCAG WFDPWGQGTLVTVSS GCCTCCACCAAGGGCCCATCGGTCTTCCCCCTGGCACCCTCCTCCAAGAGCACCTCTGGGGGCACAGCGGCCCTGGGCTGCCTGGTCAAGGACTACTTCCCCGAACCGGTGACGGTGTCGTGGAACTCAGGCGCCCTGACCAGCGGCGTGCACACCTTCCCGGCTGTCCTACAGTCCTCAGGA ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSG GCCTCCACCAAGGGCCCATCGGTCTTCCCCCTGGCACCCTCCTCCAAGAGCACCTCTGGGGGCACAGCGGCCCTGGGCTGCCTGGTCAAGGACTACTTCCCCGAACCGGTGACGGTGTCGTGGAACTCAGGCGCCCTGACCAGCGGCGTGCACACCTTCCCGGCTGTCCTACAGTCCTCAGGA ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSG GAGGTGCAGCTGGTGGAGTCTGGGGGAGGCTTGGTCCAGCCTGGGGGGTCCCTGAGACTCTCCTGTGCAGCCTCT EVQLVESGGGLVQPGGSLRLSCAAS GGATTCACCTTTAGTAGCTATTGG GFTFSSYW ATGAGCTGGGTCCGCCAGGCTCCAGGGAAAGGGCTGGAGTGGGTGGCCAAC MSWVRQAPGKGLEWVAN ATAAAGCAAGATGGAAGTGAGAAA IKQDGSEK TACTATGTGGACTCTGTGAAGGGCCGATTCACCATCTCCAGAGACAACGCCAAGAACTCACTGTATCTGCAAATGAACAGCCTGAGAGCCGAGGACACGGCTGTGTATTACTGT YYVDSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYC TGGGGCCAGGGAACCCTGGTCACCGTCTCCTCA WGQGTLVTVSS GCGAGGGATTGGGTGGAAGGGCCCTGGTTCGACCCC ARDWVEGPWFDP TGTGCGAGGGATTGGGTGGAAGGGCCCTGGTTCGACCCCTGG 42 CARDWVEGPWFDPW 14 463.037 11.095 76.078 363.264 136S296M244S 435S13N8M233S10N 447S4N47M182S 493S183M111N 2.812e-132 75.33 6.737e-18 1.222e-103 1 0.875 1 100 137 432 1 296 436 443 14 21 448 494 5 51 494 676 1 183 137 211 212 235 236 286 287 310 311 424 461 493 425 460 TTG 3 GGCC 4 False GAGGTGCAGCTGGTGGAGTCTGGGGGAGGCTTGGTCCAGCCTGGGGGGTCCCTGAGACTCTCCTGTGCAGCCTCTGGATTCACCTTTAGTAGCTATTGGATGAGCTGGGTCCGCCAGGCTCCAGGGAAAGGGCTGGAGTGGGTGGCCAACATAAAGCAAGATGGAAGTGAGAAATACTATGTGGACTCTGTGAAGGGCCGATTCACCATCTCCAGAGACAACGCCAAGAACTCACTGTATCTGCAAATGAACAGCCTGAGAGCCGAGGACACGGCTGTGTATTACTGTGCGAGGGATTGGGTGGAAGGGCCCTGGTTCGACCCCTGGGGCCAGGGAACCCTGGTCACCGTCTCCTCA EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLEWVANIKQDGSEKYYVDSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCARDWVEGPWFDPWGQGTLVTVSS 0 0 0.125 0.5 0 0 -1 -1 -1 False False CCTAAAGGTCAAACTC-1_contig_2 AGCTTCAGCTGTGGTAGAGAAGACAGGATTCAGGACAATCTCCAGCATGGCCGGCTTCCCTCTCCTCCTCACCCTCCTCACTCACTGTGCAGGGTCCTGGGCCCAGTCTGTGCTGACTCAGCCACCCTCAGCGTCTGGGACCCCCGGGCAGAGGGTCACCATCTCTTGTTCTGGAAGCAGCTCCAACATCGGAAGTAATTATGTATACTGGTACCAGCAGCTCCCAGGAACGGCCCCCAAACTCCTCATCTATAGGAATAATCAGCGGCCCTCAGGGGTCCCTGACCGATTCTCTGGCTCCAAGTCTGGCACCTCAGCCTCCCTGGCCATCAGTGGGCTCCGGTCCGAGGATGAGGCTGATTATTACTGTGCAGCATGGGATGACAGCCTGAGTCGGTCTGTGTTCGGAGGAGGCACCCAGCTGACCGTCCTCGGTCAGCCCAAGGCTGCCCCATCGGTCACTCTGTTCCCACCCTCCTCTGAGGAGCTTCAAGCCAACAAGGCCACACTGGTGTGTCTCGTAAGTGACTTCTACCCGGGAGCCGTGACAGTGGCCTGGAAGGCAGATGGCAGCCCCGTCAAGGTGGGAGTGGAGACCACCAAACCCTCCAAACAAAGCAAC human IGL False True False True False True IGLV1-47*01 IGLV1-47*01 IGLJ7*01 IGLJ7*01 IGLC7*01 CAGTCTGTGCTGACTCAGCCACCCTCAGCGTCTGGGACCCCCGGGCAGAGGGTCACCATCTCTTGTTCTGGAAGCAGCTCCAACATCGGAAGTAATTATGTATACTGGTACCAGCAGCTCCCAGGAACGGCCCCCAAACTCCTCATCTATAGGAATAATCAGCGGCCCTCAGGGGTCCCTGACCGATTCTCTGGCTCCAAGTCTGGCACCTCAGCCTCCCTGGCCATCAGTGGGCTCCGGTCCGAGGATGAGGCTGATTATTACTGTGCAGCATGGGATGACAGCCTGAGTCGGTCTGTGTTCGGAGGAGGCACCCAGCTGACCGTCCTCG CAGTCTGTGCTGACTCAGCCACCCTCAGCGTCTGGGACCCCCGGGCAGAGGGTCACCATCTCTTGTTCTGGAAGCAGCTCCAACATCGGAAGTAATTATGTATACTGGTACCAGCAGCTCCCAGGAACGGCCCCCAAACTCCTCATCTATAGGAATAATCAGCGGCCCTCAGGGGTCCCTGACCGATTCTCTGGCTCCAAGTCTGGCACCTCAGCCTCCCTGGCCATCAGTGGGCTCCGGTCCGAGGATGAGGCTGATTATTACTGTGCAGCATGGGATGACAGCCTGAGTNNNNCTGTGTTCGGAGGAGGCACCCAGCTGACCGTCCTCG QSVLTQPPSASGTPGQRVTISCSGSSSNIGSNYVYWYQQLPGTAPKLLIYRNNQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLSRSVFGGGTQLTVL QSVLTQPPSASGTPGQRVTISCSGSSSNIGSNYVYWYQQLPGTAPKLLIYRNNQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLSXXVFGGGTQLTVL 1 291 296 331 331 519 CAGTCTGTGCTGACTCAGCCACCCTCAGCGTCTGGGACCCCCGGGCAGAGGGTCACCATCTCTTGTTCTGGAAGCAGCTCCAACATCGGAAGTAATTATGTATACTGGTACCAGCAGCTCCCAGGAACGGCCCCCAAACTCCTCATCTATAGGAATAATCAGCGGCCCTCAGGGGTCCCTGACCGATTCTCTGGCTCCAAGTCTGGCACCTCAGCCTCCCTGGCCATCAGTGGGCTCCGGTCCGAGGATGAGGCTGATTATTACTGTGCAGCATGGGATGACAGCCTGAGT QSVLTQPPSASGTPGQRVTISCSGSSSNIGSNYVYWYQQLPGTAPKLLIYRNNQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLS CAGTCTGTGCTGACTCAGCCACCCTCAGCGTCTGGGACCCCCGGGCAGAGGGTCACCATCTCTTGTTCTGGAAGCAGCTCCAACATCGGAAGTAATTATGTATACTGGTACCAGCAGCTCCCAGGAACGGCCCCCAAACTCCTCATCTATAGGAATAATCAGCGGCCCTCAGGGGTCCCTGACCGATTCTCTGGCTCCAAGTCTGGCACCTCAGCCTCCCTGGCCATCAGTGGGCTCCGGTCCGAGGATGAGGCTGATTATTACTGTGCAGCATGGGATGACAGCCTGAGT QSVLTQPPSASGTPGQRVTISCSGSSSNIGSNYVYWYQQLPGTAPKLLIYRNNQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLS CTGTGTTCGGAGGAGGCACCCAGCTGACCGTCCTCG VFGGGTQLTVL CTGTGTTCGGAGGAGGCACCCAGCTGACCGTCCTCG VFGGGTQLTVL GGTCAGCCCAAGGCTGCCCCATCGGTCACTCTGTTCCCACCCTCCTCTGAGGAGCTTCAAGCCAACAAGGCCACACTGGTGTGTCTCGTAAGTGACTTCTACCCGGGAGCCGTGACAGTGGCCTGGAAGGCAGATGGCAGCCCCGTCAAGGTGGGAGTGGAGACCACCAAACCCTCCAAACAAAGCAAC GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFYPGAVTVAWKADGSPVKVGVETTKPSKQSN GGTCAGCCCAAGGCTGCCCCCTCGGTCACTCTGTTCCCACCCTCCTCTGAGGAGCTTCAAGCCAACAAGGCCACACTGGTGTGTCTCGTAAGTGACTTCTACCCGGGAGCCGTGACAGTGGCCTGGAAGGCAGATGGCAGCCCCGTCAAGGTGGGAGTGGAGACCACCAAACCCTCCAAACAAAGCAAC GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFYPGAVTVAWKADGSPVKVGVETTKPSKQSN CAGTCTGTGCTGACTCAGCCACCCTCAGCGTCTGGGACCCCCGGGCAGAGGGTCACCATCTCTTGTTCTGGAAGC QSVLTQPPSASGTPGQRVTISCSGS AGCTCCAACATCGGAAGTAATTAT SSNIGSNY GTATACTGGTACCAGCAGCTCCCAGGAACGGCCCCCAAACTCCTCATCTAT VYWYQQLPGTAPKLLIY AGGAATAAT RNN CAGCGGCCCTCAGGGGTCCCTGACCGATTCTCTGGCTCCAAGTCTGGCACCTCAGCCTCCCTGGCCATCAGTGGGCTCCGGTCCGAGGATGAGGCTGATTATTACTGT QRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYC TTCGGAGGAGGCACCCAGCTGACCGTCCTC FGGGTQLTVL GCAGCATGGGATGACAGCCTGAGTCGGTCTGTG AAWDDSLSRSV TGTGCAGCATGGGATGACAGCCTGAGTCGGTCTGTGTTC 39 CAAWDDSLSRSVF 13 455.247 nan 58.644 367.228 103S291M228S5N 398S2N36M188S 433S189M129N 5.737e-130 nan 1.095e-12 7.191e-105 1 nan 1 99.471 104 394 1 291 399 434 3 38 434 622 1 189 104 178 179 202 203 253 254 262 263 370 404 433 371 403 CGGT 4 False CAGTCTGTGCTGACTCAGCCACCCTCAGCGTCTGGGACCCCCGGGCAGAGGGTCACCATCTCTTGTTCTGGAAGCAGCTCCAACATCGGAAGTAATTATGTATACTGGTACCAGCAGCTCCCAGGAACGGCCCCCAAACTCCTCATCTATAGGAATAATCAGCGGCCCTCAGGGGTCCCTGACCGATTCTCTGGCTCCAAGTCTGGCACCTCAGCCTCCCTGGCCATCAGTGGGCTCCGGTCCGAGGATGAGGCTGATTATTACTGTGCAGCATGGGATGACAGCCTGAGTCGGTCTGTGTTCGGAGGAGGCACCCAGCTGACCGTCCTC QSVLTQPPSASGTPGQRVTISCSGSSSNIGSNYVYWYQQLPGTAPKLLIYRNNQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLSRSVFGGGTQLTVL 0 0 nan nan 0 0 -1 -1 -1 False False HT07 EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLEWVANIKQDGSEKYYVDSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCARDWVVGPWFDPWGQGTLVTVSS QSVLTQPPSASGTPGQRVTISCSGSSSNIGSNYVYWYQQLPGTAPKLLIYRNNQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLSRSVFGGGTQLTVL ['V98E'] [] False False [] [] 0 12 11 IGHG G002341_False_IGHG_402 True"},{"location":"g002_validation/","title":"Validation","text":""},{"location":"g002_validation/#validation","title":"Validation","text":"<p>The most important part of this clinical trial, other than its working, is that everything is validated. That means that the data is validated, the code is validated, and the results are validated. This is a crucial part of the process and should not be skipped.</p>"},{"location":"g002_validation/#facssorting","title":"FACS/Sorting","text":"<p>These are instructions on validating the file structure containing the FACS/Sorting data before uploading to Box.</p> :material-console-line: Command Line Usage <pre><code>#Run the validator for flow from the command line\n$ g00x g002 validate flow my_path/to/box/G002/\n</code></pre> <p>If you got your data from AWS, your command line would look like the following</p> <pre><code>#Run the validator for flow given the AWS structure\n$ g00x g002 validate g002/G002/sorting/G002\n</code></pre>  :material-api: Python <pre><code>   from g00x.flow.flow import parse_flow_data\n   from g00x.data import Data\n\n   # data\ndata = Data()\n\n   # parse flow data into a dataframe\nvalidated_structure = parse_flow_data(data,\"g002/G002/sorting/G002\") # this returns a dataframe\n</code></pre>"},{"location":"g002_validation/#file-structure","title":"File structure","text":"<p>Your folder structure on Box should look like this.</p> <pre><code># If you used the above commands to sync the data. The folder structure will look like this\n\ng002/G002/sorting\n\u2514\u2500\u2500 G002\n    \u251c\u2500\u2500 Prescreens\n    \u2502   \u251c\u2500\u2500 Prescreen_RunDate220825_UploadDate221021\n    \u2502   \u251c\u2500\u2500 Prescreen_RunDate220826_UploadDate221021\n    ....\n    \u2514\u2500\u2500 Sorts\n        \u251c\u2500\u2500 Sort_RunDate220927_UploadDate221013\n        \u251c\u2500\u2500 Sort_RunDate220928_UploadDate221014\n        \u251c\u2500\u2500 Sort_RunDate220929_UploadDate221014\n        \u251c\u2500\u2500 Sort_RunDate220930_UploadDate221014\n    ...\n</code></pre>"},{"location":"g002_validation/#full-file-structure","title":"Full file structure","text":"<p>Download full architecture via Madhu Prabhakaran</p>"},{"location":"g002_validation/#sequencing-files","title":"Sequencing files","text":"<p>To validate the sequencing files, they must be merged with the flow data. Thus, you will need both sequencing and flow files. This is because most of the metadata is housed in the flow files.</p> <p>The folder for sequencing should look like the following.</p> <pre><code>G002\n\u251c\u2500\u2500 run0002\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 221006_VH00497_31_AAAVKCLHV\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sample_manifest.csv\n\u251c\u2500\u2500 run0003\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 221019_VH00497_32_AAANGGVM5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sample_manifest.csv\n\u2514\u2500\u2500 run0004\n \u251c\u2500\u2500 221101_VL00414_3_AACFYLCM5\n \u251c\u2500\u2500 221103_VL00414_4_AAATJGYM5\n \u2514\u2500\u2500 sample_manifest.csv\n</code></pre> <p>where a <code>sample_manifest.csv</code> looks like the following.</p> pool_number sorted_date vdj_sequencing_replicate cso_sequencing_replicate vdj_lirary_replicate cso_library_replicate bio_replicate vdj_index feature_index vdj_run_id cso_run_id 0 1 220927 0 0 0 0 0 SI-TT-D6 SI-TN-D6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV 1 1 220928 0 0 0 0 0 SI-TT-E6 SI-TN-E6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV 2 1 220929 0 0 0 0 0 SI-TT-F6 SI-TN-F6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV 3 1 220930 0 0 0 0 0 SI-TT-G6 SI-TN-G6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV 4 2 220930 0 0 0 0 0 SI-TT-H6 SI-TN-H6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV <p>To run the <code>merge</code> use the following.</p> :material-console-line: Command Line Usage <pre><code>$ g00x g002 validate merge -f /path/to/flow -s /path/to/sequencing -o merge.csv\n---&gt; 100%\n</code></pre> <p>You can use the following command to merge the files if you have the AWS Structure.</p> <pre><code>$ g00x g002 validate merge -s ./g002/G002/sequencing/G002 -f ./g002/G002/sorting/G002 -o merge.csv\n---&gt; 100%\n</code></pre>  :material-api: Python <pre><code>   from g00x.sequencing.merge import merge_flow_and_sequencing\n   from g00x.data import Data\n\nout = 'merge.csv'\ndata = Data()\ndf = merge_flow_and_sequencing(data,\"path/to/flow\", \"path/to/sequencing\")\ndf.to_csv(out)\n</code></pre> <p>The merged file will use the sort pool and sorting date as the fields to join together the sequencing and flow data.</p> <p></p>"},{"location":"g002_validation/#merged-fields","title":"Merged Fields","text":"<p>Below are all the fields available in the merged file. You may view the merged file through the api <code>my_file = merge_flow_and_sequencing(data,\"path/to/flow\", \"path/to/sequencing\")</code> and then <code>my_file.data</code> to view the data.</p> Column Definition ptid The participant id, e.g. G002XXXX group The trial group, 1-4 weeks The number of weeks post-vaccine visit_id The visit id which corresponds to a weeks post vaccine probe_set Which probe was the sample sorted with, eOD or Core sample_type PBMC or GC run_date :material-merge: The date of the sort sort_pool :material-merge: Which pool was the sample put into hashtag The hashtag oligo which will be used to demultiplex run_dir_path Where the sequencing data path is located pool_number :material-merge: The pool number is the same as the sort pool sorted_date :material-merge: The date of the sort vdj_sequencing_replicate How many times has the sample been sequenced for VDJ, index starts at zero cso_sequencing_replicate How many times has the sample been sequenced for the feature library vdj_lirary_replicate How many times has the same library been prepared for the VDJ cso_library_replicate How many times has the same library been prepared for the feature bio_replicate :material-bio: A biological replicate (brand new samples) vdj_index The Illumina index to demultiplex the VDJ library feature_index The Illumina index to demultiplex the feature library vdj_run_id The Illumina assigned run id for the VDJ library cso_run_id The Illumina assigned run id for the feature library <p>An example of five entries for the merged file is below.</p> ptid group weeks visit_id probe_set sample_type run_date sort_pool hashtag run_dir_path pool_number sorted_date vdj_sequencing_replicate cso_sequencing_replicate vdj_lirary_replicate cso_library_replicate bio_replicate vdj_index feature_index vdj_run_id cso_run_id 0 G002516 1 -5 V091 eODGT8 PBMC 2022-09-27 P01 HT01 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002 P01 2022-09-27 0 0 0 0 0 SI-TT-D6 SI-TN-D6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV 1 G002516 1 4 V160 eODGT8 PBMC 2022-09-27 P01 HT02 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002 P01 2022-09-27 0 0 0 0 0 SI-TT-D6 SI-TN-D6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV 2 G002516 1 8 V200 eODGT8 PBMC 2022-09-27 P01 HT03 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002 P01 2022-09-27 0 0 0 0 0 SI-TT-D6 SI-TN-D6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV 3 G002855 2 -5 V091 eODGT8 PBMC 2022-09-28 P01 HT06 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002 P01 2022-09-28 0 0 0 0 0 SI-TT-E6 SI-TN-E6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV 4 G002855 2 4 V160 eODGT8 PBMC 2022-09-28 P01 HT07 /mnt/fsx/workspace/jwillis/repos/G00x/g002/G002/sequencing/G002/run0002 P01 2022-09-28 0 0 0 0 0 SI-TT-E6 SI-TN-E6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV <p>A downloadable merge file can be found here</p>"},{"location":"g003_analysis/","title":"Analysis","text":"<p>The analysis of the data can be done after the pipeline.</p> <p></p>"},{"location":"g003_analysis/#getting-an-analysis-report","title":"Getting an analysis report","text":"<p>The analysis report is the combined sequencing and flow cytometry data. It has all the counts and frequencies of the flow data and the frequencies of the VRC01 class among the sequences. It will then combine those frequencies to give a final frequency of VRC01 among some cell type phenotypes.</p> :material-console-line: Command Line Usage <p>The following will produce an analysis report and combine data. It will output a flow</p> <pre><code>$ g00x g003 analysis report -s g003/G003/output/final_df.feather -f g003/G003/output/flow_output.feather -o g003/G003/output/flow_and_sequencing\n</code></pre>  :material-api: Python <pre><code>   from g00x.data import Data\n   from g00x.analysis.report import combine_seq_and_flow\n\ndata = Data()\nsequencing_dataframe_path = \"g003/G003/output/final_df.feather\"\nflow_dataframe_path = \"g003/G003/output/flow_output.feather\"\n\n   # input the sequences to feather\nsequencing_dataframe = pd.read_feather(sequencing_dataframe_path)\nflow_dataframe = pd.read_feather(flow_dataframe_path)\n\n   # generate three different dataframes\nseq_and_flow_df, seq_and_flow_df_long_name, seq_and_flow_df_long_form = combine_seq_and_flow(\ndata, sequencing_dataframe, flow_dataframe\n)\n</code></pre> <p>This will output a <code>flow_and_sequencing.feather</code>, <code>flow_and_sequencing_long_names.feather</code>, and <code>flow_and_sequencing_long_form.feather</code>.</p> <p>The long form is the long form dataframe:</p> run_purpose pubID ptid group weeks visit_id probe_set sample_type value_type value short_name long_name pbmc_gate_expression calculation KWTRPG003 G003-243 G003-243 10 -5 V91 eODGT8 PBMC count 102.0 IgD+/KO-/Antigen++ B cells IgD+/KO-/Antigen++ B cells P14 KWTRPG003 G003-243 G003-243 10 8 V201 eODGT8 PBMC count 2163368.0 IgD+ B cells IgD+ B cells P6 <p>The long names are pivoted:</p> Unnamed: 0 run_purpose pubID ptid group weeks visit_id probe_set sample_type B cells Dump- IgD+ B cells IgD+/Antigen++ B cells IgD+/Antigen++/KO- B cells IgD+/KO- B Cells IgD+/KO-/Antigen++ B cells IgD- B cells IgD-/Antigen++ B cells IgD-/Antigen++/KO- B cells IgD-/IgG+/KO- IgD-/IgG-/IgM+/Antigen++ B cells IgD-/IgG-/IgM+/KO-/Antigen++ B cells IgD-/IgM+/IgG- B cells IgD-/IgM-/IgG+/Antigen++ B cells IgD-/IgM-/IgG+/Antigen++/KO- B cells IgD-/KO-/Antigen++ (sorted) B cells IgD-IgM-IgG+ B cells IgD-KO- B cells IgG-/IgM+/KO- B cells IgG-/IgM+/KO-/Antigen++ B cells IgM-/IgG+/KO-/Antigen++ B cells IgM-/IgG- B cells IgM-/IgG-/Antigen-- B cells IgM-/IgG-/KO- B cells IgM-/IgG-/KO-/Antigen-- B cells IgM-IgG-/Antigen--/KO- B cells Lymphocytes Number of IGD- sequences that are VRC01-class Number of IGHA sequences that are VRC01-class Number of IGHA1*01 sequences that are VRC01-class Number of IGHA2*01 sequences that are VRC01-class Number of IGHD sequences that are VRC01-class Number of IGHD*02 sequences that are VRC01-class Number of IGHG sequences that are VRC01-class Number of IGHG1*01 sequences that are VRC01-class Number of IGHG2*01 sequences that are VRC01-class Number of IGHG3*01 sequences that are VRC01-class Number of IGHG4*01 sequences that are VRC01-class Number of IGHM sequences that are VRC01-class Number of IGHM*01 sequences that are VRC01-class Number of IGHV1-2*02 sequences that are VRC01-class Number of IGHV1-2*04 sequences that are VRC01-class Number of IGHV1-2*05 sequences that are VRC01-class Number of IGHV1-2*06 sequences that are VRC01-class Number of sequences Number of undefined-allele sequences that are VRC01-class Percent IgA^{+}KO^- among Ag^{--} Percent IgD^{-}KO^{-} among Ag^{++} Percent IgG^{+}KO^- among Ag^{++} Percent IgM{+}KO^- among Ag^{++} Percent antigen-specific (IgD-GT8^{++}) among IgG^{+} Percent antigen-specific among IgD^- Percent antigen-specific among IgG^{+} Percent antigen-specific among IgM Percent epitope-specific (CD4bs-specific) among IgG^{+} Percent epitope-specific (KO^-Ag^{++}) among IgD^- Percent epitope-specific (KO^-Ag^{++}) among IgG^{+} Percent epitope-specific (KO^-Ag^{++}) among IgM Percent of IGD- sequences that are VRC01-class Percent of IGHA sequences that are VRC01-class Percent of IGHA1*01 sequences that are VRC01-class Percent of IGHA2*01 sequences that are VRC01-class Percent of IGHD sequences that are VRC01-class Percent of IGHD*02 sequences that are VRC01-class Percent of IGHG sequences that are VRC01-class Percent of IGHG1*01 sequences that are VRC01-class Percent of IGHG2*01 sequences that are VRC01-class Percent of IGHG3*01 sequences that are VRC01-class Percent of IGHG4*01 sequences that are VRC01-class Percent of IGHM sequences that are VRC01-class Percent of IGHM*01 sequences that are VRC01-class Percent of IGHV1-2*02 sequences that are VRC01-class Percent of IGHV1-2*04 sequences that are VRC01-class Percent of IGHV1-2*05 sequences that are VRC01-class Percent of IGHV1-2*06 sequences that are VRC01-class Percent of VRC01-class sequences among IgA Percent of VRC01-class sequences among IgD- Percent of VRC01-class sequences among IgG Percent of VRC01-class sequences among IgM Percent of undefined-allele sequences that are VRC01-class Singlets num_not_vrc01_class num_vrc01_class 58 KWTRPG003 G003-630 G003-630 10 16 V257 eODGT8 PBMC 2.85673e+06 2.92277e+06 1.60911e+06 199 165 1.60499e+06 167 1.24337e+06 4293 1617 763753 13 11 124732 4022 1470 1599 767771 1.23859e+06 124691 11 1471 328433 250 328199 112 112 3.46313e+06 57 11 11 0 0 0 45 38 2 2 3 0 0 57 0 0 0 309 1 44.8 37.666 36.549 0.00882181 0.559151 0.34527 0.523854 0.0104223 0.208265 0.128602 0.191594 0.00881891 18.4466 40.7407 40.7407 0 0 0 17.5781 19.0955 10.5263 8.69565 20 0 0 71.25 0 0 0 nan 0.0237226 0.0336786 0 7.69231 3.26462e+06 252 57 83 KWTRPG003 G003-799 G003-799 6 21 V292 eODGT8 PBMC 1.24465e+07 1.27558e+07 7.06433e+06 1401 1229 7.0634e+06 1231 5.35685e+06 15885 9990 3.16765e+06 47 42 531550 14962 9157 9930 3.18366e+06 5.34015e+06 531499 42 9169 1.63602e+06 862 1.6356e+06 710 708 1.44308e+07 404 45 45 0 0 0 358 348 2 5 3 1 1 404 0 0 0 519 0 82.1346 62.8895 61.2017 0.00790218 0.498953 0.296536 0.469962 0.00884207 0.311905 0.18537 0.288001 0.00790142 77.842 86.5385 90 0 0 0 78.1659 79.2711 40 50 75 12.5 12.5 88.4026 0 0 0 nan 0.144296 0.225119 0.000987678 0 1.40101e+07 115 404 <p>The short names are also pivoted:</p> run_purpose pubID ptid group weeks visit_id probe_set sample_type B cells Dump- IgD+ B cells IgD+/Antigen++ B cells IgD+/Antigen++/KO- B cells IgD+/KO- B Cells IgD+/KO-/Antigen++ B cells IgD- B cells IgD-/Antigen++ B cells IgD-/Antigen++/KO- B cells IgD-/IgG+/KO- IgD-/IgG-/IgM+/Antigen++ B cells IgD-/IgG-/IgM+/KO-/Antigen++ B cells IgD-/IgM+/IgG- B cells IgD-/IgM-/IgG+/Antigen++ B cells IgD-/IgM-/IgG+/Antigen++/KO- B cells IgD-/KO-/Antigen++ (sorted) B cells IgD-IgM-IgG+ B cells IgD-KO- B cells IgG-/IgM+/KO- B cells IgG-/IgM+/KO-/Antigen++ B cells IgM-/IgG+/KO-/Antigen++ B cells IgM-/IgG- B cells IgM-/IgG-/Antigen-- B cells IgM-/IgG-/KO- B cells IgM-/IgG-/KO-/Antigen-- B cells IgM-IgG-/Antigen--/KO- B cells Lymphocytes Singlets num_IGHA1*01_vrc01_class_sequences num_IGHA2*01_vrc01_class_sequences num_IGHA_vrc01_class_sequences num_IGHD*02_vrc01_class_sequences num_IGHD_vrc01_class_sequences num_IGHG1*01_vrc01_class_sequences num_IGHG2*01_vrc01_class_sequences num_IGHG3*01_vrc01_class_sequences num_IGHG4*01_vrc01_class_sequences num_IGHG_vrc01_class_sequences num_IGHM*01_vrc01_class_sequences num_IGHM_vrc01_class_sequences num_IGHV1-2*02_vrc01_class_sequences num_IGHV1-2*04_vrc01_class_sequences num_IGHV1-2*05_vrc01_class_sequences num_IGHV1-2*06_vrc01_class_sequences num_igdneg_vrc01_class_sequences num_sequences num_undefined-allele_vrc01_class_sequences percent_IGHA1*01_vrc01_class_sequences percent_IGHA2*01_vrc01_class_sequences percent_IGHA_vrc01_class_sequences percent_IGHD*02_vrc01_class_sequences percent_IGHD_vrc01_class_sequences percent_IGHG1*01_vrc01_class_sequences percent_IGHG2*01_vrc01_class_sequences percent_IGHG3*01_vrc01_class_sequences percent_IGHG4*01_vrc01_class_sequences percent_IGHG_vrc01_class_sequences percent_IGHM*01_vrc01_class_sequences percent_IGHM_vrc01_class_sequences percent_IGHV1-2*02_vrc01_class_sequences percent_IGHV1-2*04_vrc01_class_sequences percent_IGHV1-2*05_vrc01_class_sequences percent_IGHV1-2*06_vrc01_class_sequences percent_ag_among_igd_neg percent_ag_among_igg percent_ag_among_igm percent_cd4bs_among_igg percent_ep_among_igd_neg percent_ep_among_igg percent_ep_among_igm percent_gt8++_among_igg percent_igako_among_ag percent_igdneg_vrc01_class_sequences percent_iggko_among_ag percent_igmko_among_ag percent_ko_among_ag_igd_neg percent_undefined-allele_vrc01_class_sequences percent_vrc01_among_iga percent_vrc01_among_igd_neg percent_vrc01_among_igg percent_vrc01_among_igm num_not_vrc01_class num_vrc01_class KWTRPG003 G003-630 G003-630 10 10 V215 eODGT8 PBMC 3494736.0 3547169.0 1717301.0 586.0 427.0 1712345.0 430.0 1772133.0 7731.0 1924.0 1019144.0 483.0 143.0 262713.0 6813.0 1592.0 1889.0 1028967.0 1760743.0 262022.0 143.0 1599.0 465573.0 392.0 465126.0 123.0 123.0 4034868.0 3887505.0 10.0 0.0 10.0 0.0 0.0 23.0 1.0 2.0 1.0 27.0 0.0 0.0 37.0 0.0 0.0 0.0 37.0 305.0 0.0 23.25581395348837 0.0 22.22222222222222 0.0 0.0 11.330049261083744 5.555555555555555 11.11111111111111 10.0 10.843373493975903 0.0 0.0 60.65573770491803 0.0 0.0 0.0 0.43625393805092505 0.6621203595450583 0.1838508181932375 0.18358217513292457 0.10659470818499515 0.1553985696334285 0.05443202277770799 0.751336048677946 31.377551020408163 12.131147540983607 23.367092323499193 0.05457556999030616 24.886819298926397 0.0 0.01293116132080269 0.016850447309648874 0.0 268.0 37.0 KWTRPG003 G003-799 G003-799 6 21 V292 eODGT8 PBMC 12446531.0 12755837.0 7064332.0 1401.0 1229.0 7063404.0 1231.0 5356848.0 15885.0 9990.0 3167650.0 47.0 42.0 531550.0 14962.0 9157.0 9930.0 3183665.0 5340149.0 531499.0 42.0 9169.0 1636022.0 862.0 1635598.0 710.0 708.0 14430849.0 14010068.0 45.0 0.0 45.0 0.0 0.0 348.0 2.0 5.0 3.0 358.0 1.0 1.0 404.0 0.0 0.0 0.0 0.0 404.0 519.0 90.0 0.0 86.53846153846155 0.0 0.0 79.27107061503416 40.0 50.0 75.0 78.16593886462883 12.5 12.5 88.40262582056893 0.0 0.0 0.0 0.2965363213591276 0.469961506628367 0.00884206565704073 0.3119046759002596 0.18537020277596078 0.28800140718323064 0.007901420374376822 0.4989532504205059 82.13457076566125 77.84200385356455 61.20171100120305 0.007902178555368872 62.889518413597735 0.0 0.1442958803882238 0.2251190038681148 0.0009876775467971028 115.0 404.0"},{"location":"g003_analysis/#count","title":"Count","text":"<p>Easily count the amount of samples we have.</p> :material-console-line: Command Line Usage <pre><code>$ g00x g003 analysis count -f g003/G003/output/flow_output.feather -o count\n</code></pre> <p>This will output:</p> <p> </p>"},{"location":"g003_data/","title":"Getting Data from AWS","text":"<p>We store our data on AWS S3 Buckets. We have two buckets, one for G002 and one for G003. To get access to the buckets, you need to obtain credentials. Buckets are HIPAA compliant and are encrypted.</p>"},{"location":"g003_data/#obtaining-aws-credentials","title":"Obtaining AWS credentials.","text":"<p>To get AWS credentials, you can email Troy to get access.</p> <p>There are two scenarios for access.</p> <ol> <li> <p>You already have an AWS key. In that case, email us your IAM ARN and we will add you to the IAM group.</p> </li> <li> <p>You don't have an AWS account and need to be added to the SchiefLab group. In that case, you will receive an email with login instructions, your OTP (one time password) and your security credentials. The security credentials will be your AWS key and secret key and will be used to access the data programmatically</p> </li> </ol>"},{"location":"g003_data/#aws-g003","title":"AWS G003","text":"<p>To get G003 data, we use AWS buckets. The bucket <code>S3URI</code> is <code>s3://iavig003sabucket/g003/</code>. The data is organized by sequencing, sorting and output. To get the data, you need the AWS CLI.</p> <p>To get AWS CLI, follow the instructions here.</p> <p>Once you get the AWS CLI, you need to configure it. Follow the instructions here.</p> <pre><code>$ aws configure\nAWS Access Key ID [None]: Secret key in email credentials\nAWS Secret Access Key [None]: Secret key in email credentials\nDefault region name [None]: us-west-2\nDefault output format [None]: json\n</code></pre> <p>Once you are configured, we can check if you have access to the S3 bucket.</p> <pre><code>$ aws s3 ls s3://iavig003sabucket/ --region af-south-1\nPRE g003/\nPRE raw_sequences\n</code></pre> <p>G003</p> <p>You have access to the bucket if you are shown the <code>PRE g003/</code> output.</p>"},{"location":"g003_data/#aws-s3-copy-specific-files-from-aws","title":"AWS S3 Copy Specific Files from AWS","text":"<p>Below is a way to only copy certain components of the AWS bucket</p> Sorting <pre><code>$ aws s3 cp --recursive  s3://iavig003sabucket/g003/sorting/ buckets/g003/sorting\n---&gt; 100%\n</code></pre> Sequencing <p>Get all sequencing files    <pre><code>$ aws s3 cp --recursive  s3://iavig003sabucket/g003/sequencing/ buckets/g003/sequencing\n---&gt; 100%\n</code></pre> </p> <p>get the sequencing and sorting directory, excluding large bcl and fastq files    <pre><code>$ aws s3 cp --recursive s3://iavig003sabucket/g003/ ./g003/sequencing --exclude *working_directory/* --exclude *.fastq.gz --exclude *.tif --exclude *.cbcl --exclude *.imf1 --exclude *.filter --exclude *.bin --exclude *Logs/* --exclude *_stdout --exclude *_stderr --exclude *Autofocus/* --exclude *Intensities/*\n---&gt; 100%\n</code></pre> </p> Output <pre><code>$ aws s3 cp --recursive  s3://iavig003sabucket/g003/output/ buckets/g003/output\n---&gt; 100%\n</code></pre>"},{"location":"g003_data/#aws-s3-copy-local-files-to-aws","title":"AWS S3 Copy Local Files to AWS","text":"<p>Copy a directory to AWS. This will copy the entire directory and all subdirectories.</p> <pre><code>$ aws s3 cp --recursive  221118_VH00124_107_AAAW2V3HV  s3://iavig003sabucket/raw_sequnces/\n---&gt; 100%\n</code></pre> <p>221118_VH00124_107_AAAW2V3HV</p> <p>This is the flow cell directory from the sequencer. If you are an end user, update to <code>s3://iavig003sabucket/raw_sequences</code>.</p>"},{"location":"g003_data/#aws-s3-sync-all-files-from-aws","title":"AWS S3 Sync All Files from AWS","text":"<p>SYNC THE ENTIRE BUCKET!!</p> <pre><code>$ aws s3 sync --delete  s3://iavig003sabucket/ buckets/ --region af-south-1\n---&gt; 100%\n</code></pre> <p>Warning: Large File</p> <p>The entire bucket will likely be over 2 TB</p> <p>--delete</p> <p>The <code>--delete</code> flag will delete any files in the destination that are not in the source. This is useful for keeping the destination in sync with the source. If you don't want to delete files, remove the <code>--delete</code> flag.</p> <p>Sync</p> <p>The <code>sync</code> command can also be used on specific file susbsets, e.g. sorting</p> <p>s3://iavig003sabucket/g003</p> <p>The subpath <code>g003</code> is the main g003 bucket. The top level may have some other app-related things.</p>"},{"location":"g003_pipeline/","title":"10x pipeline","text":"<p>After you have a validated merged dataframe in from validation, you can begin the 10X pipeline which consists of demultiplexing, vdj, and feature counting.</p> <p></p> <p>CellRanger 7.1.0</p> <p>The cellranger version in this pipeline is 7.1.0</p>"},{"location":"g003_pipeline/#flow","title":"Flow","text":":material-console-line: Command Line Usage :material-api: Python <p>The following will analyze the flow path and output a dataframe that will be used in analysis. It computes each count of each gate that are useful in frequency analysis.</p> <p> <pre><code>$ g00x g003 pipeline flow -o g003/G003/output/flow /path/to/flow\n</code></pre> </p> <pre><code>import pandas as pd\nfrom g00x.data import Data\nfrom g00x.flow.flow import parse_flow_data\nfrom pathlib import Path\n\ndata = ctx.obj[\"data\"]\nfolder = 'path/to/flow'\nflow_data = parse_flow_data(data, folder)\nout = Path(out)\noutput_feather = Path(out.parent / (out.stem + \".feather\"))\noutput_csv = Path(out.parent / (out.stem + \".csv\"))\n</code></pre> <p>Here is what the flow dataframe will look like.</p> run_purpose run_date sort_id ptid group weeks visit_id probe_set sample_type sort_software_dv sort_file_type sample_tube gate phenotype value_type extention file_path file_subset value branch easy_name notes sort_pool hashtag 119 PreS 2022-08-25 S6C G003831 2 -5 V091 eODGT8 PBMC DV Summary T1 P11 IgD+/Antigen++ count .csv ['g003/G003/sorting/G003/Prescreens/Prescreen_RunDate220825_UploadDate221021/PopulationSummaryFilesFromDV/PreS_220825_S6C_G003831_V091_eODGT8_PBMC_DV_Summary_T1_a.csv'] ['a'] 50 IgD+ antigen_pos_igd_pos_b_cells nan 2461 PreS 2022-11-04 S6C G003136 2 8 V200 eODGT8 PBMC DV Summary T1 P13 IgD+/KO- count .csv ['g003/G003/sorting/G003/Prescreens/Prescreen_RunDate221104_UploadDate221129/PopulationSummaryFilesFromDV/PreS_221104_S6C_G003136_V200_eODGT8_PBMC_DV_Summary_T1_a.csv'] ['a'] 190682 IgD+ nan 2754 PreS 2022-11-04 S6C G003947 2 8 V200 Cg28v2 PBMC DV Summary T1 P31 IgG-IgM-/IgA+/KO- count .csv ['g003/G003/sorting/G003/Prescreens/Prescreen_RunDate221104_UploadDate221129/PopulationSummaryFilesFromDV/PreS_221104_S6C_G003947_V200_Cg28v2_PBMC_DV_Summary_T1_a.csv'] ['a'] 10498 IgA+ nan 4485 Sort 2022-10-25 S6C G003831 2 4 V160 eODGT8 PBMC DV Summary T1 P27 IgG-IgM-IgD- count .csv ['g003/G003/sorting/G003/Sorts/Sort_RunDate221025_UploadDate221101/ClinicalSamples/PopulationSummaryFilesFromDV/Sort_221025_S6C_G003831_V160_eODGT8_PBMC_HT02_DV_Summary_T1_P03_a.csv'] ['a'] 100696 nan P03 HT02 2343 PreS 2022-11-04 S6C G003136 2 -5 V091 eODGT8 PBMC DV Summary T1 P12 IgD+/Antigen++/KO- count .csv ['g003/G003/sorting/G003/Prescreens/Prescreen_RunDate221104_UploadDate221129/PopulationSummaryFilesFromDV/PreS_221104_S6C_G003136_V091_eODGT8_PBMC_DV_Summary_T1_a.csv'] ['a'] 47 IgD+ epitope_pos_igd_pos_b_cells_rev nan"},{"location":"g003_pipeline/#demultiplexing","title":"Demultiplexing","text":"<p>The input to the demultiplexing part of the pipeline will be the sequencing and flow file paths</p> :material-console-line: Command Line Usage :material-api: Python <p> <pre><code>$ g00x g003 pipeline demultiplex -o g003/G003/output/demultiplex -f /path/to/flow -s /path/to/sequencing\n</code></pre> </p> <pre><code>import pandas as pd\nfrom g00x.data import Data\nfrom g00x.sequencing.tenX import run_demultiplex\n\nflow_path = \"path/to/flow\"\nsequencing_path = \"path/to/sequencing\"\ndata = Data()\nmerged_dataframe: pd.DataFrame = merge_flow_and_sequencing(data, flow_path, sequencing_path)  # type: ignore\ndemultiplex_df = run_demultiplex(data, merged_dataframe, out, overwrite)\ndemultiplex_df.to_csv(\"demultiplex.csv\")\ndemultiplex_df.to_csv(\"demultiplex.feather\")\n</code></pre> <p>The demulitplex algorithm will add the following fields in demultiplex output</p> Column Definition vdj_run_dir The full path to the vdj run directory, e.g. the Illumina directory cso_run_dir The full path to the cso run directory, e.g. the Illumina directory vdj_sample_name The unique vdj sample name given to each row cso_sample_name The unique cso sample name given to each row vdj_fastq_dir The full path to the vdj fastq directory cso_fastq_dir The full path to the cso fastq directory <p>An example demultiplexing output dataframe is found below.</p> ptid group weeks visit_id probe_set sample_type run_date sort_pool hashtag run_dir_path pool_number sorted_date vdj_sequencing_replicate cso_sequencing_replicate vdj_lirary_replicate cso_library_replicate bio_replicate vdj_index feature_index vdj_run_id cso_run_id vdj_run_dir_path cso_run_dir_path vdj_fastq_dir vdj_sample_name cso_fastq_dir cso_sample_name 0 G003516 1 -5 V091 eODGT8 PBMC 2022-09-27 P01 HT01 /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002 P01 2022-09-27 0 0 0 0 0 SI-TT-D6 SI-TN-D6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path vdj-SI-TT-D6 /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path cso-SI-TN-D6 1 G003516 1 4 V160 eODGT8 PBMC 2022-09-27 P01 HT02 /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002 P01 2022-09-27 0 0 0 0 0 SI-TT-D6 SI-TN-D6 221006_VH00497_31_AAAVKCLHV 221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002/221006_VH00497_31_AAAVKCLHV /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path vdj-SI-TT-D6 /mnt/fsx/workspace/jwillis/repos/G00x/g003/G003/sequencing/G003/run0002/working_directory/demultiplexed/29cc0e71cb9200226957921707138c5c/outs/fastq_path cso-SI-TN-D6"},{"location":"g003_pipeline/#vdj","title":"VDJ","text":"<p>The output of demultiplexing pipeline will be used as input, see the pipeline</p> :material-console-line: Command Line Usage :material-api: Python <p>The following will run the VDJ pipeline from the demultiplex dataframe and output vdj.feather inside of the output folder.</p> <p> <pre><code>Run it from demultiplexed dataframe\n$ g00x g003 pipeline vdj -o g003/G003/output/vdj -d output/demultiplexed.feather\n</code></pre> </p> <p>You can run the same with the following python code.</p> <pre><code>from g00x.sequencing.tenX import run_vdj\nfrom g00x.data import Data\n\ndata = Data()\ndemultiplex_dataframe = pd.read_feather(demultiplex_dataframe_path)\nrun_vdj(data, demultiplex_dataframe, out)\n</code></pre> <p>The output vdj dataframe will only contain one additional field</p> Column Definition vdj_output The full path to the vdj output folder"},{"location":"g003_pipeline/#cso","title":"CSO","text":"<p>This CSO pipeline will run the cellranger count part and output a feature matrix. It also uses the demultiplex.feather as input.</p> :material-console-line: Command Line Usage :material-api: Python <p>The following will run the CSO pipeline from the demultiplex dataframe and output cso.feather inside of the output folder.</p> <p> <pre><code>Run it from demultiplexed dataframe\n$ g00x g003 pipeline cso -o g003/G003/output/cso -d output/demultiplexed.feather\n</code></pre> </p> <p>You can run the same with the following python code.</p> <pre><code>from g00x.sequencing.tenX import run_cso\nfrom g00x.data import Data\n\ndata = Data()\ndemultiplex_dataframe = pd.read_feather(demultiplex_dataframe_path)\nrun_cso(data, demultiplex_dataframe, out)\n</code></pre> <p>The output cso dataframe will only contain one additional field</p> Column Definition cso_output The full path to the cso output folder"},{"location":"g003_pipeline/#airr","title":"AIRR","text":"<p>The output of the VDJ and CSO can now be combined to get a final sequencing dataframe. This is the final sequencing dataframe that will be used for the analysis.</p> <p>The AIRR protocol does the following.</p> <p>It will...</p> <ol> <li>Run SADIE AIRR on the VDJ contigs to get a formalized AIRR dataframe.</li> <li>Analyze the feature barcodes and assign cellids to the correct participant.</li> <li>Add the PubIDs to the AIRR dataframe.</li> <li>Run mutational analysis</li> <li>Run iGL assignment to all sequences</li> <li>Determine if sequence is VRC01 class</li> <li>Add mutational sets (find what mutations are VRC01-like)</li> <li>Cluster sequences</li> <li>Determine isotype</li> </ol> :material-console-line: Command Line Usage :material-api: Python <p>The following will run the AIRR pipeline from the VDJ and CSO dataframes and output airr.feather inside of the output folder.</p> <p> <pre><code>Run it from VDJ and CSO dataframes\n$ g00x g003 pipeline airr -o g003/G003/output/airr -v output/vdj.feather -c output/cso.feather\n</code></pre> </p> <p>You can run the same with the following python code.</p> <pre><code>from g00x.data import Data\nfrom g00x.sequencing.airr import run_airr\n\nvdj_out = 'output/vdj.feather'\ncso_out = 'output/cso.feather'\ndata = Data()\nvdj_dataframe = pd.read_feather(vdj_out)\ncso_dataframe = pd.read_feather(cso_out)\noutput_df = run_airr(data, vdj_dataframe, cso_dataframe, out, overwrite)\n</code></pre> <p>An output dataframe will take the following:</p> <p>|       | cellid                                     | pubID    | ptid      | group | weeks | visit_id | probe_set | sample_type | run_date   | sort_pool | hashtag | run_dir_path                                                            | pool_number | sorted_date | vdj_sequencing_replicate | cso_sequencing_replicate | vdj_lirary_replicate | cso_library_replicate | bio_replicate | vdj_index | feature_index | vdj_run_id                  | cso_run_id                  | vdj_run_dir_path                                                                                    | cso_run_dir_path                                                                                    | vdj_fastq_dir                                                                                                                                            | vdj_sample_name | cso_fastq_dir                                                                                                                                            | cso_sample_name | vdj_output                                                                                                    | cso_output                                                                                                    | sadie_airr_path                                                                                                                       | paired_sadie_airr_path                                                                                                                       | cellhash           | sequence_id_heavy           | sequence_heavy                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | reference_name_heavy | locus_heavy | stop_codon_heavy | vj_in_frame_heavy | v_frameshift_heavy | productive_heavy | rev_comp_heavy | complete_vdj_heavy | v_call_top_heavy | v_call_heavy | d_call_top_heavy | d_call_heavy | j_call_top_heavy | j_call_heavy | c_call_heavy | sequence_alignment_heavy                                                                                                                                                                                                                                                                                                                                                  | germline_alignment_heavy                                                                                                                                                                                                                                                                                                                                                  | sequence_alignment_aa_heavy                                                                                              | germline_alignment_aa_heavy                                                                                              | v_alignment_start_heavy | v_alignment_end_heavy | d_alignment_start_heavy | d_alignment_end_heavy | j_alignment_start_heavy | j_alignment_end_heavy | c_alignment_start_heavy | c_alignment_end_heavy | v_sequence_alignment_heavy                                                                                                                                                                                                                                                                               | v_sequence_alignment_aa_heavy                                                                      | v_germline_alignment_heavy                                                                                                                                                                                                                                                                               | v_germline_alignment_aa_heavy                                                                      | d_sequence_alignment_heavy | d_sequence_alignment_aa_heavy | d_germline_alignment_heavy | d_germline_alignment_|</p>"},{"location":"g003_validation/","title":"Validation","text":"<p>The following discusses data structure and validation.</p>"},{"location":"g003_validation/#data-structure","title":"Data structure","text":"<p>The data stored in our bucket is structured as follows in the <code>s3://iavig003sabucket/g003/</code> bucket.</p> <pre><code>\u251c\u2500\u2500 g001\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sequencing\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 run0001\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 run0002\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sorting\n\u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 Sorts\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 output\n\u2514\u2500\u2500 g003\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sequencing\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 run0001\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 run0002\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 run0003\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 run0004\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sorting\n\u2502\u00a0\u00a0 \u2502    \u2514\u2500\u2500 Sorts\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 output\n</code></pre>"},{"location":"g003_validation/#sequencing","title":"Sequencing","text":"<p>The sequencing folder structure takes the following file structure.</p> <pre><code>g001/sequencing/\n\u251c\u2500\u2500 run0001\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 221118_VH00124_107_AAAW2V3HV\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sequencing_manifest.csv\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 working_directory\n\u2514\u2500\u2500 run0002\n    \u251c\u2500\u2500 230201_NB552490_0042_AHKY7KBGXM\n    \u251c\u2500\u2500 sequencing_manifest.csv\n    \u2514\u2500\u2500 working_directory\n</code></pre> <p>Each sequencing run is uploaded numerically runXXXX. Each run folder contains a <code>sequencing_manifest.csv</code> file that looks like:</p> ptid timpoint sorted_date cells hto vdj_index cso_index pool_number run_id 0 PubID_023 V08 221107 5076 C0251 SI-TT-G1 SI-TN-A1 1 221118_VH00124_107_AAAW2V3HV 1 PubID_187 V08 221107 290 C0252 SI-TT-G2 SI-TN-A2 2 221118_VH00124_107_AAAW2V3HV 2 PubID_153 V08 221107 1222 C0253 SI-TT-G2 SI-TN-A2 2 221118_VH00124_107_AAAW2V3HV 3 PubID_046 V08 221107 288 C0254 SI-TT-G2 SI-TN-A2 2 221118_VH00124_107_AAAW2V3HV 4 PubID_023 V08 221107 4993 C0251 SI-TT-G3 SI-TN-A3 3 221118_VH00124_107_AAAW2V3HV 5 PubID_110 V08 221108 3183 C0255 SI-TT-G4 SI-TN-A4 1 221118_VH00124_107_AAAW2V3HV 6 PubID_154 V08 221108 5000 C0256 SI-TT-G5 SI-TN-A5 2 221118_VH00124_107_AAAW2V3HV 7 PubID_154 V08 221108 1560 C0256 SI-TT-G6 SI-TN-A6 3 221118_VH00124_107_AAAW2V3HV 8 PubID_047 V08 221108 1480 C0257 SI-TT-G7 SI-TN-A7 4 221118_VH00124_107_AAAW2V3HV 9 PubID_047 V08 221108 1811 C0257 SI-TT-G8 SI-TN-A8 5 221118_VH00124_107_AAAW2V3HV 10 PubID_079 V08 221108 1625 C0258 SI-TT-G9 SI-TN-A9 6 221118_VH00124_107_AAAW2V3HV <p>Where each field is defined as:</p> Column Definition ptid The participant id timpoint The timepoint of the sequencing sorted_date The date it was sorted <code>YYMMDD</code> format cells The number of cells in the GEM reaction hto The hashtag number e.g. <code>HT01</code> vdj_index The index used for the VDJ library cso_index The index used for the hashtag library pool_number The pool number of the gem reaction vdj_run_id The Illumina flow-cell id that the VDJ library was run on cso_run_id The Illumina flow-cell id that the hashtag library was run on <p>Info</p> <p>Often, the VDJ and CSO library will be on the same flow-cell ID.</p>"},{"location":"g003_validation/#sorting","title":"Sorting","text":"<p>The sorting directory takes the following file structure.</p> <pre><code>g001/sorting/\n\u2514\u2500\u2500 Sorts\n    \u251c\u2500\u2500 Sort_RunDate221118_UploadDate221222\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 ClinicalSamples\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 DataFilesFromMelody\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 SortHCT019a_221107_M1_PubID_023_V8_eODGT8_PBMC_Chorus_Data_T1_P1_a.fcs\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 SortHCT019a_221107_M1_PubID_023_V8_eODGT8_PBMC_Chorus_Data_T1_P3_b.fcs\n                ..\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 DataStats\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 SortHCT019a_221107_M1_PubID_023_V8_eODGT8_PBMC_Chorus_Summary_T1_P1_a.xlsx\n    \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 SortHCT019a_221107_M1_PubID_023_V8_eODGT8_PBMC_Chorus_Summary_T1_P3_b.xlsx\n                ..\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 ScreenshotsCounts\n                ..\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 ScreenshotsMelodyStats\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 SortHCT019a_221107_M1_PubID_023_V8_eODGT8_PBMC_Chorus_Summary_T1_P1_a.png\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 SortHCT019a_221107_M1_PubID_023_V8_eODGT8_PBMC_Chorus_Summary_T1_P3_b.png\n</code></pre> <p>Each sort data upload can have multiple sorts. Each upload will have the upload date and sort date, e.g. <code>Sort_RunDate221118_UploadDate221222</code>.</p> <p>There are four sub-directories:</p> <ol> <li><code>ClinicalSamples/DataFilesFromMelody</code> - The FCS files from the sort</li> <li><code>ClinicalSamples/DataStats</code> - The summary statistics from the sort calculated in FlowJo.</li> <li><code>ClinicalSamples/ScreenshotsCounts</code> - The screenshots of the counts of the sort.</li> <li><code>ClinicalSamples/ScreenshotsMelodyStats</code> - The screenshots of the gating.</li> </ol> <p>Notice each file name has the following format, e.g. <code>SortHCT019a_221107_M1_PubID_023_V8_eODGT8_PBMC_Chorus_Summary_T1_P1_a.xlsx</code></p> Field Definition Sort The sort name e.g. <code>SortHCT019a</code> Date The date the sort was performed <code>YYMMDD</code> Machine The machine number e.g. <code>M1</code> ptid The participant id Visit The visit number e.g. <code>V08</code> sort_probe The sort probe e.g. <code>eODGT8</code> sample_type The sample type e.g. <code>PBMC</code> software The software used e.g. <code>Chorus</code> type The type of file e.g. <code>Summary</code> tube_number The tube number e.g. <code>T1</code> pool_number The pool number e.g. <code>P1</code> file_subset The file subset e.g. <code>a</code>"}]}
